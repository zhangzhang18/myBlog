<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[优雅的处理NullPointerExcepter]]></title>
    <url>%2FmyBlog%2F2019%2F10%2F16%2FOptional%2F</url>
    <content type="text"><![CDATA[Optional是Java8提供的为了解决null安全问题的一个API。 阿里巴巴编码规约-异常处理 12345678910说明：本手册明确防止 NPE 是调用者的责任。 10. 【推荐】防止 NPE，是程序员的基本修养，注意 NPE 产生的场景： 1）返回类型为基本数据类型，return 包装数据类型的对象时，自动拆箱有可能产生 NPE。 反例：`public int f() &#123; return Integer 对象&#125;`， 如果为 null，自动解箱抛 NPE。 2） 数据库的查询结果可能为 null。 3） 集合里的元素即使 isNotEmpty，取出的数据元素也可能为 null。 4） 远程调用返回对象时，一律要求进行空指针判断，防止 NPE。 5） 对于 Session 中获取的数据，建议 NPE 检查，避免空指针。 6） 级联调用 `obj.getA().getB().getC()；`一连串调用，易产生 NPE。 正例：使用 JDK8 的 Optional 类来防止 NPE 问题。 一：Optional类方法 1. 创建 Optional 相关方法方法：Optional.of、Optional.ofNullable、Optional.empty()： 1`Optional emptyOptional = Optional.empty(); Optional nonEmptyOptional = Optional.of(&quot;name&quot;); Optional nonEmptyOptional = Optional.ofNullable(null); ` 2. 检查 Optional 值方法：Optional.isPresent()、Optional.ifPresent() 如果 Optional有值，isPresent() 返回 true ifPresent() 如果值存在，则执行代码块 3. 通过 Optional 取值 get() 返回值包含在 Optional 中返回，（建议配合isPresent() 使用，假如 Optional 不包含一个值, get() 将会抛出一个异常） orElse() 如果值不存在，则返回默认值 orElseGet() 与 orElse() 类似，如果 Optional 不包含值，用函数作为返回值 orElseThrow() 与 orElseGet() 类似，监测到值为 null 时抛出异常 4. map转换值：Stream和Optional 的map方法对比图 Stream和optional的fiatMap方法对比图可以把Optional看成包含一个元素的Stream对象。5. filter1`String name = &quot;Aa&quot;; Optional optionalName = Optional.of(name).filter(str -&gt; str.length() &gt; 2);` 注意： 无法序列化由于Optional 类设计时就没特别考虑将其作为类的字段使用，所以它也并未实现Serializable；把 Optional 类型用作属性或是方法参数在 IntelliJ IDEA 中更是强力不推荐的用Optional 声明域模型中某些类型是不错的主意。如果非要实现序列化的模型域，可以参考下例 基于值的类（说明：这是一个基于值的class类，对于同一性（特性）敏感的操作 （包含引用的相等性如:==）,同一性的hashcode或者同步等等、对optional实例可能会产生不可预料的结果，这种结果应该被避免。）https://docs.oracle.com/javase/8/docs/api/java/lang/doc-files/ValueBased.html 这里说的是基于值的类需要满足以下几点： 1、 final类型和不可变的（可能会包含可变对象的引用）2、 有equals、hashCode、toString方法的实现，它是通过实例的状态计算出来的，而并不会通过其它的对象或变量去计算。3、 不会使用身份敏感的操作，比如在二个实例之间引用相等性、hashCode或者内在的锁。4、 判断二个值相等仅仅通过equal方法，而不会通过==去判断。5、 它不提供构造方法，它通过工厂方法创建它的实例，这不保证返回实例的一致性。6、 当它们相等时，它是可以自由替换的。如果x和y 调用equal方法返回true，那么可以将x和y任意交换，它的结果不会产生任何变化。 二：实战示例1. 用Optional封装可能为Null的值 假设有一个Map&lt;String,Object&gt;方法； 如果map 没有关联的key，就会返回null。 1Object value = map.get(&quot;key&quot;); 可以替换成 1Optional&lt;Object&gt; value = Optional.ofNullable(map.get(&quot;key&quot;)); 2. 作为返回值（不建议作为参数）3. 把所有内容整合起来三：增强 Java 9 or()：如果值存在，返回包含该值的 Optional 对象；否则，返回 or() 函数生成的 Optional 对象。 ifPresentOrElse(Consumer&lt;? super T&gt;action, Runnable emptyAction)：如果值存在，使用该值执行指定调用，否则使用空值执行调用。 stream()：如果值存在，返回该值的顺序流（Stream）；否则返回空流。 Java 10 orElseThrow()：如果值存在，返回该值；否则抛出NoSuchElementException。注意：与 Java 8 不同，不接受任何参数。 Java 11 isEmpty()：如果值不存在，返回 true；否则返回 false。]]></content>
      <categories>
        <category>NoteBook</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库索引]]></title>
    <url>%2FmyBlog%2F2019%2F10%2F09%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B4%A2%E5%BC%95%2F</url>
    <content type="text"><![CDATA[索引，用于提升数据库的查找速度。 索引主要是基于Hash表和B+树。 加速查找速度的数据结构，常见的有两类： (1)哈希，例如HashMap，查询/插入/修改/删除的平均时间复杂度都是O(1)； (2)树，例如平衡二叉搜索树，查询/插入/修改/删除的平均时间复杂度都是O(lg(n))； 如果是单行查询确实是哈希索引更快。对于group by 、order by 、比较&lt;&gt;哈希索引时间复杂度会退化成O(n)，而树的有序性，依旧能保持O(logn)的高效率。 一般来说，索引本身也很大，不可能全部存储在内存中，因此索引往往以索引文件的形式存储的磁盘上。 磁盘里的数据加载到内存的时候，是以页为单位加载的，节点与节点之间的数据是不联系的，所以不同的节点，很可能分布在不同磁盘页中， 磁盘的加载次数和树的高度是关联的。越矮加载次数越少。 二叉查找树：最坏的情况，磁盘IO次数等于索引树的高度。为了减少磁盘IO次数，把原本“瘦高”的树变得“矮胖”，这是b-树的特征。 ## b树 是一种多路平衡查找树（多叉查找树），它的每一个节点最多包含K个子孩子，K被称为B树的阶，K的大小取决于磁盘页大小。 首先从根节点进行二分查找，如果找到就返回对应节点数据，否则对相应区间的指针指向的节点进行递归进行查找，直到找到节点或者找到null。 M阶的B-树特征： 根节点至少有两个子节点。 每个中间节点都包含K-1个元素和K个孩子。m/2&lt;=k&lt;=m 每个叶子节点都包含K-1个元素。m/2&lt;=k&lt;=m 所有叶子节点都位于同一层。 每个节点中的元素从大到小排序，节点中K-1个元素正好是K个孩子包含的元素的值域分划。 应用：文件系统，数据库索引（MongoDB） B+树是基于B-树的变体，比B-树查询性能更高。 特点： 有K个子树的中间节点包含有K个元素（B树是K-1个元素），每个元素不保存数据，只用来索引，所有数据保存在叶子节点。 所有叶子节点中包含了全部元素信息，及指向含有这些元素的指针，且叶子节点本身依关键字的大小自小而大顺序链接。 所有的中间节点元素都同时存在于子节点，在子节点元素中是最大或者最小元素。 父节点元素都出现在子节点，所有叶子节点包含了全量元素信息。（根节点到某个节点的路径长度一样） 每个子节点都带有指向下一个节点的信息，形成一个有序的链表。（不需要中序遍历） B+树比B-树更加矮胖，因此查询时的IO次数更少。 B+树查询最终查找到叶子节点，B-树只要找到匹配元素即可。 B-树的查找性能会不稳定（最好时根节点，最差是叶子节点），B+每次查找都是稳定的。 对于范围查找B+优势更加明显。 相比较B-树B+树的优势有三个： IO次数更少 查询性能更稳定 范围查询简便 InnoDB不支持哈希索引 参考漫画：B-树 漫画：B+树 红黑树 MySql索引实现原理]]></content>
      <categories>
        <category>NoteBook</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[MQ归纳]]></title>
    <url>%2FmyBlog%2F2019%2F09%2F18%2FMQ%E5%BD%92%E7%BA%B3%2F</url>
    <content type="text"><![CDATA[MQ]]></content>
      <categories>
        <category>NoteBook</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis归纳]]></title>
    <url>%2FmyBlog%2F2019%2F08%2F18%2FRedis%E5%BD%92%E7%BA%B3%2F</url>
    <content type="text"><![CDATA[Redis一个基于内存的高性能的key-value数据库。 数据结构：String字符串，Hash字典，List列表，Set集合，SortedSet有序集合。 使用Redis有哪些好处？ (1) 速度快，因为数据存在内存中，类似于HashMap，HashMap的优势就是查找和操作的时间复杂度都是O(1) (2) 支持丰富数据类型，支持string，list，set，sorted set，hash (3) 支持事务，操作都是原子性，所谓的原子性就是对数据的更改要么全部执行，要么全部不执行 (4) 丰富的特性：可用于缓存，消息，按key设置过期时间，过期后将会自动删除 2.为什么redis需要把所有数据放到内存中? Redis为了达到最快的读写速度将数据都读到内存中，并通过异步的方式将数据写入磁盘。所以redis具有快速和数据持久化的特征。如果不将数据放在内存中，磁盘I/O速度为严重影响redis的性能。在内存越来越便宜的今天，redis将会越来越受欢迎。 如果设置了最大使用的内存，则数据已有记录数达到内存限值后不能继续插入新值。 3.Redis是单进程单线程的为什么也那么快？ Redis快的主要原因是： 完全基于内存 数据结构简单，对数据操作也简单 使用多路 I/O 复用模型 采用单线程，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗 CPU，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗； 这里“多路”指的是多个网络连接，“复用”指的是复用同一个线程。采用多路 I/O 复用技术可以让单个线程高效的处理多个连接请求（尽量减少网络 IO 的时间消耗），且 Redis 在内存中操作数据的速度非常快，也就是说内存内的操作不会成为影响Redis性能的瓶颈，主要由以上几点造就了 Redis 具有很高的吞吐量。 4.Redis锁的使用。 1234567891011121314151617181920212223242526272829private static Redisson redisson = RedissonManager.getRedisson(); private static final String LOCK_FLAG = &quot;mylock_&quot;; /** * 根据name对进行上锁操作，redissonLock 阻塞的，采用的机制发布/订阅 * @param key */ public static void lock(String key)&#123; String lockKey = LOCK_FLAG + key; RLock lock = redisson.getLock(lockKey); //lock提供带timeout参数，timeout结束强制解锁，防止死锁 ：1分钟 lock.lock(1, TimeUnit.MINUTES); logger.info(&quot;lock key:&#123;&#125;&quot;,lockKey); &#125; /** * 根据name对进行解锁操作 * @param key */ public static void unlock(String key)&#123; String lockKey = LOCK_FLAG + key; RLock lock = redisson.getLock(lockKey); //如果锁被当前线程持有，则释放 if(lock.isHeldByCurrentThread())&#123; lock.unlock(); logger.info(&quot;unlock key:&#123;&#125;&quot;,lockKey); &#125; &#125;]]></content>
      <categories>
        <category>NoteBook</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[垃圾收集器]]></title>
    <url>%2FmyBlog%2F2019%2F08%2F05%2F%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%2F</url>
    <content type="text"><![CDATA[两个收集器之间存在连线，说明它们可以搭配使用。 1. Serial 新生代收集器，单线程，复制算法 单线程，不仅仅说明它只会用一个CPU或一条收集线程去完成垃圾手机工作，更重要的时进行垃圾收集时，必须暂停其他说有的工作线程，直至收集结束。Stop The World优点：简单而高效，没有线程交互的开销。 2. ParNew 是Serial的多线程版本，复制算法 与Serial可用的所有控制参数、收集算法、Stop The World、对象分配原则、回收策略完全一样，实现上，两种收集器共用了相当多的代码。 ParNew在单CPU环境中绝对不会有比Serial更好的效果。注：并发强调的是一起出发（交替执行），并行强调的是一起执行。 3. Parallel Scavenge 新生代收集器，多线程，复制算法 关注点与其他收集器不同，CMS关注尽可能缩短垃圾收集时用户线程停顿时间，而Parallel Scavenge目的时达到一个可控制的吞吐量。就是CPU用于运行用户线程的时间与CPU总消耗时间的比值，吞吐量=运行用户代码时间/（运行用户代码时间+垃圾收集时间） 停顿时间短适合与用户交互的程序，良好的响应速度能提升用户体验，高吞吐量可以高效的利用CPU时间，尽快完成运算任务，主要适合后台运算而不需要太多交互任务。 4. Serial Old 是Serial老年代版本，单线程，标记-整理算法 主要意义是给Client模式下的虚拟机使用。 5. Parallel Old 是Parallel Scavenge老年代版本，多线程，标记整理 6. CMS(Concurrent Mark Sweep) 标记-清除算法 互联网网站或者B/S系统服务端，注重服务的相应速度，希望系统停顿时间最短。 分为四个步骤： 初始标记：标记一下GC Roots能直接关联到的对象，速度很快。 并发标记：进行GC Roots Tracing的过程。与用户线程同时运行。 重新标记：为了修正并发标记期间因为用户程序继续运行导致标记产生变动的那部分对象的标记记录，这个阶段停顿时间会比初始标记阶段稍长，但是比并发标记时间短。 并发清除：与用户线程同时运行。由于整个过程耗时最长的并发标记和并发清楚过程收集器线程可以与用户线程一起工作，所以，总体上来说CMS收集器的内存回收过程是与用户线程一起并发执行的。 三个明显缺点 对CPU资源非常敏感。并发设计都对CPU资源敏感，并发阶段虽然不会导致用户线程变慢，但是会因为占用一部分线程而导致应用程序变慢，总吞吐量会降低。 无法处理浮动垃圾。由于并发清理阶段用户线程还在运行，伴随程序运行就会有新的垃圾不断产生，这部分垃圾出现在标记过程之后，CMS午发在当次收集中处理掉它们，只好下次GC时清理，这部分垃圾称为“浮动垃圾”。 基于标记-清除算法实现的，就意味着收集结束会有大量的空间碎片，空间碎片多，会给大对象分配带来很大麻烦，往往会出现老年代空间还有很大空间剩余，但是无法找到足够大的空间来分配当前对象，不得不触发Full GC。7.G1 面向服务端引用，未来可以替代CMS的收集器与其他GC收集器比较，特点 并行和并发：缩短Stop The World 停顿时间，其他收集器原本需要停顿Java线程执行GC堆，G1仍然可以通过并发的方式让Java程序继续执行。 分代收集：与其他收集器相同，分代概念在G1依然得以保留。但是采用不同方式处理。 空间整合：与CMS使用‘标记-清除’不同，G1从整体来看使用的是“标记-整理”实现。从局部（两个Region之间）使用的是“复制”实现，G1的运作期间不会产生空间碎片。 可预测的停顿：这是相对于CMS的优势。 G1之前的其他收集器进行收集范围是整个新生代和老年代，使用G1收集器，Java对的内存布局就与其他收集器有很大差别，它将整个java内存分为多个大小相等的独立区域（Region），虽然保留新生代老年代的概念，但新生代和老年代不再是物理隔离的，他们都是一部分Region（不需要连续）的集合。 运作步骤 初始标记(Initial Marking) 并发标记(Concurrent Marking) 最终标记(Final Marking) 筛选回收(Live Data Counting and Evacuation)：对Region的回收价值和成本进行排序，根据用户的期望的GC停顿时间制定回收计划。 这个阶段可以做到与用户程序一起并发执行，但是因为只回收一部分Region，时间是用户可控的，而且停顿用户现场将大幅度提高收集效率。 内存分配策略 对象优先在Eden分配 大对象直接进入老年代：避免Eden区及两个Survivor区之间发生大量的内存复制 长期存活的对象将进入老年代：在Eden出生，经历过一次GC仍然存活，并且能被Survivor容纳，将被移动到Survivor空间，设置对象年龄为1，每熬过一次GC年龄增加一岁，年龄增加到一定程度（通常15岁），就会晋升老年代。MaxTenuringThreshold配置。 动态对象年龄判定：如果在Survivor空间相同年龄所有对象的大小总和打于Survivor空间大小的一半，年龄大于或者等于该对象年龄可以直接进入老年代，无需等到MaxTenuringThreshold。 空间分配担保：发生GC之前，虚拟机会检查老年代最大可用的连续空间是否打于新生代所有对象总空间，如果这个条件成立，就可以确保是安全的。（老年代能容纳Survivor晋升到老年代的对象） 选择server模式的VM。服务端常使用 -Xms2g 设置堆内存最小值2G -Xmx2g 设置堆内存最大值2G -Xmn1g 设置新生代大小1G -Xss1024K 设置单线程栈空间大小1024K -XX:PermSize=256m 设置永久代初始大小256m。JDK8中已移除 -XX:MaxPermSize=512m 设置永久代最大值512m。JDK8中已移除 -XX:ParallelGCThreads=8 设置并行收集器收集时使用的CPU数。并行收集线程数 8。 -XX:+UseConcMarkSweepGC 开启CMS收集器，默认新生代收集器 UseParNewGC。 -XX:+UseParNewGC 开启ParNew收集器。 -XX:+UseCMSCompactAtFullCollection 开启对老年代空间进行压缩整理（默认开启）。 -XX:SurvivorRatio=4 Eden与一个Surivivor的比值大小。默认为8:1:1，即Eden占8/10。 -XX:MaxTenuringThreshold=10 晋升老年代的最大年龄。默认为15，比如设为10，则对象在10次普通GC后将会被放入年老代。 -XX:CMSInitiatingOccupancyFraction=80 触发CMS收集器的内存比例。比如80%的意思就是说，当内存达到80%，就会开始进行CMS并发收集。 -XX:NewRatio 表示新生代与老年代所占的比值为1:4，Xms=Xmx并且设置了Xmn的情况下，该参数不需要进行设置。 参考：java常用命令gc发生场景jvm参数大全内存区域垃圾收集JVM内存设置多大合适？JVM 内存区域大小参数设置 ​]]></content>
      <tags>
        <tag>JAVA</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[线程池]]></title>
    <url>%2FmyBlog%2F2019%2F05%2F01%2F%E7%BA%BF%E7%A8%8B%E6%B1%A0%2F</url>
    <content type="text"><![CDATA[为什么使用多线程 降低资源消耗 -事先创建若干个线程放在容器中，当使用的时候不需要自行创建，使用完不是去销毁而是归还到容器，减少了线程创建和销毁的时间 提高线程的可管理性 -无限制的创建线程，不仅消耗资源还降低系统稳定性，线程池可以进行统一分配，监控 提高相应速度 -不需要等待线程创建 参数说明ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,TimeUnit unit,BlockingQueue&lt;Runnable workQueue) corePoolSize（最大核心线程数）： 线程池启动后，在池中保持的线程的最小数量maxinumPoolSize（线程池能容纳的最大线程数量）： 核心线程数 + 非核心线程数 = 最大线程数量unit： keepAliveTime的时间单位，可以是纳秒，毫秒，秒，分钟等keepAliveTime： 线程的最大生命周期workQueue： 任务队列threadFactory： 定义如何启动一个线程，可以设置线程的名称，并且可以确定是否是后台线程等。 new ThreadFactoryBuilder().setNameFormat(&quot;XX-task-%d&quot;).build();RejectedExecutionHandler： 拒绝任务处理器。由于超出线程数量和队列容量而对继续增加的任务进行处理的程序。 workQueue： ArrayBlockingQueue：基于数组结构的有界队列，先进先出（FIFO）原则对元素排序 LinkedBlockingQueue：基于链表结构的阻塞队列，先进先出排序元素，吞吐量高于数组结构。Executors.newFixedThreadPool() 使用这个队列 SynchronousQueue：不存储元素的阻塞队列，每个插入操作必须等到下一个线程调用一处操作，否则插入操作一直处于阻塞状态，吞吐量高于2，Executors.newCachedThreadPool()使用这个队列 PriorityBlockQueue：具有优先级的无线阻塞队列 DelayQueue（延时队列）：任务到来时，首先先加入到队列中，只有达到了指定的延时时间，才会执行任务 - RejectedExecutionHandler：** AbortPolicy（默认策略）:直接拒绝抛异常（RejectedExecutionException） CallerRunsPolicy:不抛弃任务，只有调用者所在线程来运行任务 DiscardOldestPolicy:丢弃队列最近的任务，并执行当前任务 DiscardPolicy:不处理，丢弃掉，不抛异常 总结 线程数量未达到 corePoolSize，则新建一个线程（核心线程）执行任务。 线程数量达到了 corePoolsSize，则将任务移入队列等待。 队列已满，新建非核心线程（先进先出）执行任务。 队列已满，总线程数又达到了 maximumPoolSize，就会由 RejectedExecutionHandler 抛出异常。 阿里巴巴JAVA开发手册【3】. 【强制】线程资源必须通过线程池提供，不允许在应用中自行显式创建线程。说明：使用线程池的好处是减少在创建和销毁线程上所消耗的时间以及系统资源的开销，解决资源不足的问题。如果不使用线程池，有可能造成系统创建大量同类线程而导致消耗完内存或者“过度切换”的问题。【4】. 【强制】线程池不允许使用 Executors 去创建，而是通过 ThreadPoolExecutor 的方式，这样的处理方式让写的同学更加明确线程池的运行规则，规避资源耗尽的风险。说明：Executors 返回的线程池对象的弊端如下： 1）FixedThreadPool 和 SingleThreadPool:允许的请求队列长度为 Integer.MAX_VALUE，可能会堆积大量的请求，从而导致 OOM。 2）CachedThreadPool 和 ScheduledThreadPool:允许的创建线程数量为 Integer.MAX_VALUE，可能会创建大量的线程，从而导致 OOM。 合理的配置线程池可以从以下几个角度分析： 任务的性质：CPU密集型任务、IO密集型任务、混合型任务。 任务的优先级：高、中、低。 任务的执行时间：长、中、短。 任务的依赖性：是否依赖其他系统资源，如数据库连接等。 最佳线程数目 = （线程等待时间与线程CPU时间之比 + 1）* CPU数目可以得出一个结论：线程等待时间所占比例越高，需要越多线程。线程CPU时间所占比例越高，需要越少线程。 CPU密集型时，任务可以少配置线程数，大概和机器的cpu核数相当，这样可以使得每个线程都在执行任务 IO密集型时，大部分线程都阻塞，故需要多配置线程数，2*cpu核数 建议使用有界队列：增加系统稳定性和预警能力。]]></content>
      <categories>
        <category>NoteBook</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[并发多线程]]></title>
    <url>%2FmyBlog%2F2019%2F04%2F20%2F%E5%B9%B6%E5%8F%91%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[一：JAVA内存模型（JMM）线程通信内存模型 synchronized原理使用实现机制volatile原理使用实现机制二：并发基础AQSCAS三：锁ReenTrantLock可重入锁ReenTrantReadWriteLock读写锁Condition四：并发工具类CyclicBarrierCountDownLatch五：其他六：并发集合七：atomic原子八：阻塞队列九：线程池]]></content>
      <categories>
        <category>NoteBook</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring-Boot]]></title>
    <url>%2FmyBlog%2F2019%2F03%2F11%2FSpring-Boot%2F</url>
    <content type="text"><![CDATA[Spring Boot解决得问题 配置、部署、监控变得简单。 Boot只需要很少得配置（@Configuration），项目快速搭建，主流框架无配置集成。 核心功能 独立运行Spring项目 内嵌servlet容器 - SpringApplication.run() 提供starter简化maven配置 自动装配Spring 准生产的应用监控 无代码生产和xml配置]]></content>
      <categories>
        <category>NoteBook</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AB测技术]]></title>
    <url>%2FmyBlog%2F2019%2F02%2F13%2FAB%E6%B5%8B%E6%8A%80%E6%9C%AF%2F</url>
    <content type="text"><![CDATA[简单来说，就是为同一个目标制定两个方案（比如两个页面）]]></content>
      <categories>
        <category>NoteBook</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[CAP原则-Base理论]]></title>
    <url>%2FmyBlog%2F2019%2F02%2F10%2FCAP%E5%8E%9F%E5%88%99-Base%E7%90%86%E8%AE%BA%2F</url>
    <content type="text"><![CDATA[CAP原则：分布式的三个指标， 这三个指标不可能同时做到。这个结论就叫做 CAP 定理。 Consistency（一致性）： 写操作之后的读操作，必须返回该值 Availability（可用性）： 意思是只要收到用户的请求，服务器就必须给出回应 Partition tolerance（分区容错）： 大多数分布式系统都分布在多个子网络。每个子网络就叫做一个区（partition）。分区容错的意思是，区间通信可能失败 一般来说，分区容错无法避免，因此可以认为 CAP 的 P 总是成立。CAP 定理告诉我们，剩下的 C 和 A 无法同时做到。 CA为什么不能同时成立？因为可能通信失败（分区容错） Base理论：BASE是Basically Available（基本可用）、Soft state（软状态）和Eventually consistent（最终一致性）的简写 基本可用： 指分布式系统在出现故障的时候，允许损失部分可用性（例如响应时间、功能上的可用性），允许损失部分可用性。需要注意的是，基本可用绝不等价于系统不可用。 最终一致性：最终一致性强调的是系统中所有的数据副本，在经过一段时间的同步后，最终能够达到一个一致的状态。因此，最终一致性的本质是需要系统保证最终数据能够达到一致，而不需要实时保证系统数据的强一致性 软状态：指允许系统存在中间状态，而该中间状态不会影响系统整体可用性。分布式存储中一般一份数据会有多个副本，允许不同副本同步的延时就是软状态的体现。mysql replication的异步复制也是一种体现。 总的来说，BASE理论面向的是大型高可用可扩展的分布式系统，和传统事务的ACID特性使相反的，它完全不同于ACID的强一致性模型，而是提出通过牺牲强一致性来获得可用性，并允许数据在一段时间内是不一致的，但最终达到一致状态。但同时，在实际的分布式场景中，不同业务单元和组件对数据一致性的要求是不同的，因此在具体的分布式系统架构设计过程中，ACID特性与BASE理论往往又会结合在一起使用。 聊聊分布式存储——轻松理解Raft 一：Eureka二：Zookeeper三：Consul Eureka 典型的 AP,作为分布式场景下的服务发现的产品较为合适，服务发现场景的可用性优先级较高，一致性并不是特别致命。其次 CA 类型的场景 Consul,也能提供较高的可用性，并能 k-v store 服务保证一致性。 而Zookeeper,Etcd则是CP类型 牺牲可用性，在服务发现场景并没太大优势； Eureka Zookeeper Consul GitHub https://github.com/Netflix/eureka https://github.com/apache/zookeeper https://github.com/hashicorp/consul 服务健康度检查 服务状态，内存，硬盘等 (弱)长连接，keepalive 连接心跳 多数据中心 — 支持 支持 k-v存储服务 — 支持 支持 一致性 — paxos（Paxos算法是保证在分布式系统中写操作能够顺利进行，保证系统中大多数状态是一致的，没有机会看到不一致，因此，Paxos算法的特点是一致性&gt;可用性。） rafthttp://raft.taillog.cn/ cap ap cp ca 多语言能力 http（sidecar） 客户端 支持http和dns watch支持 支持 long polling/大部分增量 — metrics 自身监控 metrics — metrics 安全 — acl acl /https SpringCloud集成 已支持 已支持 已支持]]></content>
      <categories>
        <category>NoteBook</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Spring-Cloud]]></title>
    <url>%2FmyBlog%2F2019%2F01%2F24%2FSpring-Cloud%2F</url>
    <content type="text"><![CDATA[Spring Cloud简介 Spring Cloud是一个基于Spring Boot实现的云应用开发工具，它为基于JVM的云应用开发中涉及的配置管理、服务发现、断路器、智能路由、微代理、控制总线、全局锁、决策竞选、分布式会话和集群状态管理等操作提供了一种简单的开发方式。 微服务 简单的说，微服务架构就是将一个完整的应用从数据存储开始垂直拆分成多个不同的服务，每个服务都能独立部署、独立维护、独立扩展，服务与服务间通过诸如RESTful API的方式互相调用。 优势 每个服务都比较简单，只关注一个业务功能 微服务架构方式是松耦合的，可以提供更高的灵活性 每个微服务可由不同团队独立开发，互不影响，加快推出市场速度4.允许在频繁发布不同服务的同时，保持其他部分的可用性和稳定性问题 运维开销的成本增加 系统复杂度变高 部署的速度变慢 分布式系统的冗余问题 分布式系统的复杂性 服务治理 Spring Cloud应用中可以支持多种不同的服务治理框架，比如：Netflix Eureka、Consul、Zookeeper Spring Cloud Eureka是Spring Cloud Netflix项目下的服务治理模块。 Spring Cloud Ribbon是基于Netflix Ribbon实现的一套客户端负载均衡的工具。它是一个基于HTTP和TCP的客户端负载均衡器。它可以通过在客户端中配置ribbonServerList来设置服务端列表去轮询访问以达到均衡负载的作用。 Spring Cloud Feign是一套基于Netflix Feign实现的声明式服务调用客户端。它使得编写Web服务客户端变得更加简单。我们只需要通过创建接口并用注解来配置它既可完成对Web服务接口的绑定。它具备可插拔的注解支持，包括Feign注解、JAX-RS注解。它也支持可插拔的编码器和解码器。Spring Cloud Feign还扩展了对Spring MVC注解的支持，同时还整合了Ribbon和Eureka来提供均衡负载的HTTP客户端实现。]]></content>
      <categories>
        <category>NoteBook</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ZooKeeper]]></title>
    <url>%2FmyBlog%2F2018%2F12%2F26%2FZooKeeper%2F</url>
    <content type="text"><![CDATA[分布式协调服务-可以在分布式系统中共享配置，协调锁资源，提供命名服务 Zookeeper的数据模型：像数据结构中的树，也像文件系统中的目录 Znode：包含数据，子节点引用，访问权限等。每个节点的数据最大不能超过1MBZookeeper包含的基本操作 create：创建节点 delete：删除节点 exists：判断节点是否存在 getData：获得一个节点的数据 setData：设置一个节点的数据 getChildren：获取节点下的所有子节点 Zookeeper一致性 Zookeeper Service集群是一主多从结构，更新数据时，首先跟新到主节点，在同步从节点。读取数据的时候可以读取任意节点 Zookeeper应用场景： 分布式协调服务 分布式锁 服务注册与发现 共享配置和状态信息 Zookeeper IBM小灰 什么是ZooKeeper？]]></content>
      <categories>
        <category>NoteBook</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>ZK</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elasticsearch]]></title>
    <url>%2FmyBlog%2F2018%2F12%2F06%2FElasticsearch%2F</url>
    <content type="text"><![CDATA[elasticsearch权威指南 面向文档在应用程序中对象很少只是一个简单的键和值的列表。通常，它们拥有更复杂的数据结构，可能包括日期、地理信息、其他对象或者数组等。Elasticsearch是面向文档(document oriented)的，这意味着它可以存储整个对象或文档(document)。然而它不仅仅是存储，还会索引(index)每个文档的内容使之可以被搜索。在Elasticsearch中，你可以对文档（而非成行成列的数据）进行索引、搜索、排序、过滤。这种理解数据的方式与以往完全不同，这也是Elasticsearch能够执行复杂的全文搜索的原因之一。 JSONElasticsearch 使用 JavaScript Object Notation 或者 JSON 作为文档的序列化格式。 Elasticsearch集群可以包含多个索引(indices)（数据库），每一个索引可以包含多个类型(types)（表），每一个类型包含多个文档(documents)（行），然后每个文档包含多个字段(Fields)（列）。 所以为了创建员工目录，我们将进行如下操作： 为每个员工的文档(document)建立索引，每个文档包含了相应员工的所有信息。 每个文档的类型为employee。 employee类型归属于索引megacorp。 megacorp索引存储在Elasticsearch集群中。 http://git.daojia-inc.com/jiazheng/jzup-brain.git实际上这些都是很容易的（尽管看起来有许多步骤）。我们能通过一个命令执行完成的操作：PUT /megacorp/employee/11234567&#123; "first_name": "John", "last_name": "Smith", "age": 25, "about": "I love to go rock climbing", "interests": ["sports", "music"]&#125; 我们看到path:/megacorp/employee/1包含三部分信息：名字说明megacorp索引名employee类型名1这个员工的ID 我们通过HTTP方法GET来检索文档，同样的，我们可以使用DELETE方法删除文档，使用HEAD方法检查某文档是否存在。如果想更新已存在的文档，我们只需再PUT一次。 我们尝试一个最简单的搜索全部员工的请求： GET /megacorp/employee/_search 这种方法常被称作查询字符串(query string)搜索，因为我们像传递URL参数一样去传递查询语句： GET /megacorp/employee/_search?q=last_name:Smith 使用DSL语句查询DSL(Domain Specific Language特定领域语言)以JSON请求体的形式出现。我们可以这样表示之前关于“Smith”的查询: GET /megacorp/employee/_search1234567&#123; "query": &#123; "match": &#123; "last_name": "Smith" &#125; &#125;&#125; 这会返回与之前查询相同的结果。 更复杂的搜索 我们的语句将添加过滤器(filter),它使得我们高效率的执行一个结构化搜索： GET /megacorp/employee/_search123456789101112131415161718&#123; "query": &#123; "filtered": &#123; "filter": &#123; "range": &#123; "age": &#123; "gt": 30 //1 &#125; &#125; &#125;, "query": &#123; "match": &#123; "last_name": "smith"//2 &#125; &#125; &#125; &#125;&#125; 这部分查询属于区间过滤器(range filter),它用于查找所有年龄大于30岁的数据——gt为”greater than”的缩写。 这部分查询与之前的match语句(query)一致。 现在我们的搜索结果只显示了一个32岁且名字是“Jane Smith”的员工：全文搜索到目前为止搜索都很简单：搜索特定的名字，通过年龄筛选。让我们尝试一种更高级的搜索，全文搜索——一种传统数据库很难实现的功能。我们将会搜索所有喜欢“rock climbing”的员工： GET /megacorp/employee/_search1234567&#123; "query" : &#123; "match" : &#123; "about" : "rock climbing" &#125; &#125;&#125; 解释了Elasticsearch如何在各种文本字段中进行全文搜索，并且返回相关性最大的结果集。相关性(relevance)的概念在Elasticsearch中非常重要，而这个概念在传统关系型数据库中是不可想象的，因为传统数据库对记录的查询只有匹配或者不匹配。 短语搜索目前我们可以在字段中搜索单独的一个词，这挺好的，但是有时候你想要确切的匹配若干个单词或者短语(phrases)。例如我们想要查询同时包含”rock”和”climbing”（并且是相邻的）的员工记录。要做到这个，我们只要将match查询变更为match_phrase查询即可: GET /megacorp/employee/_search1234567&#123; "query": &#123; "match_phrase": &#123; "about": "rock climbing" &#125; &#125;&#125; 高亮我们的搜索很多应用喜欢从每个搜索结果中高亮(highlight)匹配到的关键字，这样用户可以知道为什么这些文档和查询相匹配。在Elasticsearch中高亮片段是非常容易的。让我们在之前的语句上增加highlight参数： GET /megacorp/employee/_search123456789101112&#123; "query": &#123; "match_phrase": &#123; "about": "rock climbing" &#125; &#125;, "highlight": &#123; "fields": &#123; "about": &#123;&#125; &#125; &#125;&#125; 当我们运行这个语句时，会命中与之前相同的结果，但是在返回结果中会有一个新的部分叫做highlight，这里包含了来自about字段中的文本，并且用来标识匹配到的单词。]]></content>
      <categories>
        <category>NoteBook</category>
      </categories>
      <tags>
        <tag>ES</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式锁]]></title>
    <url>%2FmyBlog%2F2018%2F11%2F10%2F%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%2F</url>
    <content type="text"><![CDATA[什么是分布式将系统差分成不同的服务然后将这些服务放在不同服务器减轻单台服务的压力，提高性能和并发量。 并发并行？ 顺序执行：你吃饭吃到一半，电话来了，你一直到吃完了以后才去接，这就说明你不支持并发也不支持并行。 并行：你吃饭吃到一半，电话来了，你停了下来接了电话，接完后继续吃饭，这说明你支持并发。 并发：你吃饭吃到一半，电话来了，你一边打电话一边吃饭，这说明你支持并行。 并发强调的是一起出发（交替执行），并行强调的是一起执行。 并发的反义是顺序，并行的反义是串行。 并发并行并不是互斥概念，只不过并发强调任务的抽象调度，并行强调任务的实际执行。 分布式=高并发=多线程？ 分布式：是为了解决单个物理服务器容量和性能瓶颈问题而采用的优化手段。 该领域需要解决的问题极多，在不同技术层面上，包括：分布式文件系统、缓存、数据库、计算等。 水平拓展：当一台机器扛不住流量时，通过添加机器的方式，将流量均分。 垂直拆分：前端有多种需求时，一台机器扛不住，可以将不同需求分发到不同机器上。 高并发：反应的是 [同时有多少量]，例如直播服务，同时可能有上万人观看。 高并发可以用分布式技术去解决，将并发流量分到不同物理机器上。 例如使用缓存技术和前端将静态资源放在CDN等；还可以用多线程技术将一台服务器的能力最大化。 多线程：是指从软件或硬件上实现多个线程并发执行的技术。 多线程聚焦于如何使用编程语言将CPU能力最大化。 什么是锁为了实现多个线程在同一时刻同一代码块只能有一个线程可执行，需要在某个地方做标记，这个标记必须满足所有的线程可见，标记不存在的时候设置标记，后续的线程发现已标记则等待拥有标记的线程结束，同步代码块取消标记后，在尝试设置标记，这个标记可以理解为锁。 什么是分布式锁单体单机部署的系统被演化成分布式集群系统后，系统可能会有多份并且部署在不同的机器上，这些资源已经不是在线程之间共享了，而是属于进程之间共享的资源。指在分布式的部署环境下，通过锁机制来让多客户端互斥的对共享资源进行访问。 分布式的 CAP 理论： 任何一个分布式系统都无法同时满足一致性（Consistency）、可用性（Availability）和分区容错性（Partition tolerance），最多只能同时满足两项。 分布式锁要满足哪些要求呢 互斥性：在任意时刻，只有一个客户端能持有锁。 不会发生死锁：即使有一个客户端在持有锁的期间崩溃而没有主动解锁，也能保证后续其他客户端能加锁。 容错性：获取或释放锁的机制必须高可用且性能佳 解铃还须系铃人：加锁和解锁必须是同一个客户端，客户端自己不能把别人加的锁给解了。 分布式锁实现方式为了保证数据的最终一致性，需要很多的技术方案来支持，比如分布式事务、分布式锁等。有的时候，我们需要保证一个方法在同一时间内只能被同一个线程执行。 基于数据库实现分布式锁；基于缓存（Redis等）实现分布式锁；基于Zookeeper实现分布式锁； 基于数据库思路：在数据库中创建一个表，表中包含方法名等字段，并在方法名字段上创建唯一索引，想要执行某个方法，就使用这个方法名向表中插入数据，成功插入则获取锁，执行完成后删除对应的行数据释放锁。 基于Redis1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162import java.util.Collections;import redis.clients.jedis.Jedis;import redis.clients.jedis.JedisPool;public class XttblogLock &#123; private static final String LOCK_SUCCESS = "OK"; private static final String SET_IF_NOT_EXIST = "NX"; private static final String SET_WITH_EXPIRE_TIME = "PX"; private static final Long RELEASE_SUCCESS = 1L; private static void validParam(JedisPool jedisPool, String lockKey, String requestId, int expireTime) &#123; if (null == jedisPool) &#123; throw new IllegalArgumentException("jedisPool obj is null"); &#125; if (null == lockKey || "".equals(lockKey)) &#123; throw new IllegalArgumentException("lock key is blank"); &#125; if (null == requestId || "".equals(requestId)) &#123; throw new IllegalArgumentException("requestId is blank"); &#125; if (expireTime &lt; 0) &#123; throw new IllegalArgumentException("expireTime is not allowed less zero"); &#125; &#125; public static boolean tryLock(JedisPool jedisPool, String lockKey, String requestId, int expireTime) &#123; validParam(jedisPool, lockKey, requestId, expireTime); Jedis jedis = null; try &#123; jedis = jedisPool.getResource(); String result = jedis.set(lockKey, requestId, SET_IF_NOT_EXIST, SET_WITH_EXPIRE_TIME, expireTime); if (LOCK_SUCCESS.equals(result)) &#123; return true; &#125; &#125; catch (Exception e) &#123; throw e; &#125; finally &#123; if (null != jedis) &#123; jedis.close(); &#125; &#125; return false; &#125; public static boolean unLock(JedisPool jedisPool, String lockKey, String requestId) &#123; validParam(jedisPool, lockKey, requestId, 1); String script = "if redis.call('get', KEYS[1]) == ARGV[1] then return redis.call('del', KEYS[1]) else return 0 end"; Jedis jedis = null; try &#123; jedis = jedisPool.getResource(); Object result = jedis.eval(script, Collections.singletonList(lockKey),Collections.singletonList(requestId)); if (RELEASE_SUCCESS.equals(result)) &#123; return true; &#125; &#125; catch (Exception e) &#123; throw e; &#125; finally &#123; if (null != jedis) &#123; jedis.close(); &#125; &#125; return false; &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657import java.util.concurrent.TimeUnit;import org.redisson.Redisson;import org.redisson.core.RLock;import org.slf4j.Logger;import org.slf4j.LoggerFactory;public class RedissonLockUtil &#123; private static final Logger logger = LoggerFactory.getLogger(RedissonLockUtil.class); private static Redisson redisson = RedissonManager.getRedisson(); private static final String LOCK_FLAG = "recruitlock_"; /** * 根据name对进行上锁操作，redissonLock 阻塞的，采用的机制发布/订阅 * @param key */ public static void lock(String key)&#123; String lockKey = LOCK_FLAG + key; RLock lock = redisson.getLock(lockKey); //lock提供带timeout参数，timeout结束强制解锁，防止死锁 ：1分钟 lock.lock(1, TimeUnit.MINUTES); logger.info("lock key:&#123;&#125;",lockKey); &#125; /** * 根据name对进行解锁操作 * @param key */ public static void unlock(String key)&#123; String lockKey = LOCK_FLAG + key; RLock lock = redisson.getLock(lockKey); if (lock.isHeldByCurrentThread()) &#123; lock.unlock(); logger.info("unlock , key:&#123;&#125;"+lockKey); &#125; &#125; /** * @param key * @param millisToWait 等待获取锁的时间--单位：秒 */ public static boolean tryLock(String key, long millisToWait) &#123; String lockKey = LOCK_FLAG + key; logger.info("get redis lock start , key:&#123;&#125;"+lockKey); RLock lock = redisson.getLock(lockKey); logger.info("get redis lock end , key:"+lockKey); try &#123; return lock.tryLock(millisToWait,5000, TimeUnit.MILLISECONDS); &#125; catch (Exception e) &#123; logger.error("try lock error,key is:&#123;&#125;", lockKey, e); &#125; logger.info("get redis lock false , key:"+lockKey); return false; &#125;&#125; 错误示例12345Long result = jedis.setnx(lockKey, requestId); if (result == 1) &#123; // 若在这里程序突然崩溃，则无法设置过期时间，将发生死锁 jedis.expire(lockKey, expireTime); &#125; https://www.cnblogs.com/seesun2012/p/9214653.html http://www.cnblogs.com/linjiqin/p/8003838.html https://www.xttblog.com/?p=3171 https://juejin.im/post/5c01532ef265da61362232ed]]></content>
      <categories>
        <category>NoteBook</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dubbo]]></title>
    <url>%2FmyBlog%2F2018%2F10%2F15%2FDubbo%2F</url>
    <content type="text"><![CDATA[Dubbo 工作原理：服务注册、注册中心、消费者、代理通信、负载均衡； Dubbo Dubbo集群容错 一般的mvc项目 包含 Controller、Servicei、ServiceImpl、dao三层使用doubbo我们可以把项目拆分：Controller 作为 “消费着” 一个项目ServiceImpl +dao 作为 “提供者” 一个项目 Service “接口” 可以作为一个项目 https://github.com/doocs/advanced-java/blob/master/docs/distributed-system/dubbo-operating-principle.md Dubbo缺省协议采用单一长连接和NIO异步通讯，适合于小数据量大并发的服务调用，以及服务消费者机器数远大于服务提供者机器数的情况。 节点角色说明： * Provider: 暴露服务的服务提供方。 * Consumer: 调用远程服务的服务消费方。 * Registry: 服务注册与发现的注册中心。 * Monitor: 统计服务的调用次调和调用时间的监控中心。 * Container: 服务运行容器。 ### 工作流程 第一步：provider向注册中心注册服务 第二部：consumer从注册中心订阅服务，注册中心会通知consumer注册好的服务 第三部：consumer调用provider 第四步：provider和consumer都异步通知监控中心 调用关系说明：* 服务容器负责启动，加载，运行服务提供者。 * 服务提供者在启动时，向注册中心注册自己提供的服务。 * 服务消费者在启动时，向注册中心订阅自己所需的服务。 * 注册中心返回服务提供者地址列表给消费者，如果有变更，注册中心将基于长连接推送变更数据给消费者。 * 服务消费者，从提供者地址列表中，基于软负载均衡算法，选一台提供者进行调用，如果调用失败，再选另一台调用。 * 服务消费者和提供者，在内存中累计调用次数和调用时间，定时每分钟发送一次统计数据到监控中心。 Dubbo 负载均衡策略 1.random load balance：随机调用实现负载均衡，可以对 provider不同实例设置不同的权重，会按照权重来负载均衡，权重越大分配流量越高。 2.roundrobin loadbalance:均匀的打到各个机器，可以将性能差的机器权重小一点。 3.leastactive loadbalance：自动感知，如果某个机器性能越差，那么接收的请求越少，越不活跃，此时就会给不活跃的性能差的机器更少的请求。 4.consistanthash loadbalance：一致性 Hash 算法，相同参数的请求一定分发到一个 provider 上去，provider 挂掉的时候，会基于虚拟节点均匀分配剩余的流量，抖动不会太大。如果需要的不是随机负载均衡，是要一类请求都到一个节点，那就走这个一致性 Hash 策略。 Dubbo 集群容错策略 1.failover cluster ：失败自动切换，自动重试其他机器，默认就是这个，常见于读操作。（失败重试其它机器）&lt;dubbo:service retries=&quot;2&quot; /&gt; 2.failfast cluster ：一次调用失败就立即失败，常见于幂等性写操作。（调用失败就立即失败） 3.failsafe cluster ：出现异常时忽略掉，常用于不重要的接口调用，比如记录日志。 4.failback cluster ：失败了后台自动记录请求，然后定时重发，比较适合于写消息队列这种。 5.forking cluster ：并行调用多个 provider，只要一个成功就立即返回。常用于实时性要求比较高的读操作，但是会浪费资源。 6.broadcast cluster：逐个调用所有的 provider。通常用于通知所有提供者更新缓存或日志等本地资源信息。 序列化与反序列化序列化：把对象转换为字节序列的过程称为对象的序列化。 反序列化：把字节序列恢复为对象的过程称为对象的反序列化。 序列化对于远程调用的响应速度、吞吐量、网络带宽消耗等同样也起着至关重要的作用，是我们提升分布式系统性能的最关键因素之一。 dubbo序列化：阿里尚未开发成熟的高效java序列化实现，阿里不建议在生产环境使用它 hessian2序列化：hessian是一种跨语言的高效二进制序列化方式。但这里实际不是原生的hessian2序列化，而是阿里修改过的hessian lite，它是dubbo RPC默认启用的序列化方式 json序列化：目前有两种实现，一种是采用的阿里的fastjson库，另一种是采用dubbo中自己实现的简单json库，但其实现都不是特别成熟，而且json这种文本序列化性能一般不如上面两种二进制序列化。 java序列化：主要是采用JDK自带的Java序列化实现，性能很不理想。 在通常情况下，这四种主要序列化方式的性能从上到下依次递减。面向生产环境的应用中，建议目前更优先选择Kryo。&lt;dubbo:protocol name=&quot;dubbo&quot; serialization=&quot;kryo&quot;/&gt;Dubbo中使用高效的Java序列化 通信协议：dubbo：单一长连接，进行NIO异步通信，基于**hessian**序列化协议。（长连接，通俗说就是建立连接之后可以持续发送请求，无需再建立连接）使用场景是传输数据量小（100kb以内），并发量高。 rmi：java 的二进制序列化，适用于文件传输。 hessian：hessian序列化 http：json序列化 webservice：soap文本序列化 服务治理：1.调用链路自动生成 2.服务访问压力及时长服务降级：服务A调用服务B，B挂掉了，A重试几次还是不行，降级，走一个备用逻辑返回给用户。失败重试超时重试：consumer调用provider失败了，可以重试，或者调用超时了也可以重试。 注册中心挂了还可以继续通信：因为刚开始初始化的时候，消费者会将服务提供者的地址拉取到本地。 用 Spring 配置声明暴露服务123456789101112131415161718192021&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:dubbo="http://code.alibabatech.com/schema/dubbo" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd"&gt; &lt;!-- 提供方应用信息，用于计算依赖关系 --&gt; &lt;dubbo:application name="hello-world-app" /&gt; &lt;!-- 使用multicast广播注册中心暴露服务地址 --&gt; &lt;dubbo:registry address="multicast://224.5.6.7:1234" /&gt; &lt;!-- 用dubbo协议在20880端口暴露服务 --&gt; &lt;dubbo:protocol name="dubbo" port="20880" /&gt; &lt;!-- 声明需要暴露的服务接口 --&gt; &lt;dubbo:service interface="com.alibaba.dubbo.demo.DemoService" ref="demoService" /&gt; &lt;!-- 和本地bean一样实现服务 --&gt; &lt;bean id="demoService" class="com.alibaba.dubbo.demo.provider.DemoServiceImpl" /&gt;&lt;/beans&gt; 加载Spring配置Provider.java12345678910import org.springframework.context.support.ClassPathXmlApplicationContext;public class Provider &#123; public static void main(String[] args) throws Exception &#123; ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext(new String[]&#123;"http://10.20.160.198/wiki/display/dubbo/provider.xml"&#125;); context.start(); System.in.read(); // 按任意键退出 &#125;&#125; 服务消费者通过Spring配置引用远程服务consumer.xml12345678910111213&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans"xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"xmlns:dubbo="http://code.alibabatech.com/schema/dubbo"xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd"&gt;&lt;!-- 消费方应用名，用于计算依赖关系，不是匹配条件，不要与提供方一样 --&gt;&lt;dubbo:application name="consumer-of-helloworld-app" /&gt;&lt;!-- 使用multicast广播注册中心暴露发现服务地址 --&gt;&lt;dubbo:registry address="multicast://224.5.6.7:1234" /&gt;&lt;!-- 生成远程服务代理，可以和本地bean一样使用demoService --&gt;&lt;dubbo:reference id="demoService" interface="com.alibaba.dubbo.demo.DemoService" /&gt;&lt;/beans&gt; 加载Spring配置，并调用远程服务Consumer.java12345678910111213141516import org.springframework.context.support.ClassPathXmlApplicationContext;import com.alibaba.dubbo.demo.DemoService;public class Consumer &#123; public static void main(String[] args) throws Exception &#123; ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext(new String[] &#123;"http://10.20.160.198/wiki/display/dubbo/consumer.xml"&#125;); context.start(); DemoService demoService = (DemoService)context.getBean("demoService"); // 获取远程服务代理 String hello = demoService.sayHello("world"); // 执行远程方法 System.out.println( hello ); // 显示调用结果 &#125;&#125;]]></content>
      <categories>
        <category>NoteBook</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>Dubbo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[慢查询优化]]></title>
    <url>%2FmyBlog%2F2018%2F09%2F13%2F%E6%85%A2%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[一：慢查询原因 查询语句中存在计算逻辑 全表查询没有命中索引，或者没有索引 二：慢查询通常解决方式1.检查是否正确使用并命中索引 2.避免使用select -解析过程会将转换所有列名，消耗更多的时间 3.Order By语句优化 - 使用的列建立索引 避免使用计算表达式 4.Group By 优化 - 筛选条件在Group By之前过滤掉 5.使用Exists代替in - in会导致全表扫描，连续的数值可以用Between And 6.使用varchar/nvarchard代替char/nchar - 变长字段的存储空间小 7.能用Union All 就不用Union - Union并集，会去除重复数据 8.索引不是越多越好 - 会降低 Insert和Update效率 索引类型 A. 主键索引（PRIMARY KEY） 建表的时候同时创建主键索引 B.唯一索引（UNIQUE） 索引列的值必须唯一，允许为空ALTER ​ TABLE table_name ADD UNIQUE (column) C.普通索引 ​ ALTER TABLE table_name ADD INDEX index_name (column) D.组合索引 包含多个列 ​ ALTER TABLE table_name ADD INDEX index_name(column1, column2, column3) E.全文索引 利用分词技术多种算法智能分析文本中关键词的频率和重要性 ​ ALTER TABLE table_name ADD FULLTEXT (column) 建索引原则​ A. 最左匹配原则 ​ -多列索引。总是从最前面开始，接着往后，中间不能跳过。 ​ 通常把使用最频繁的列放在最左边 ​ B.选择区分度高的列 ​ C.索引列不能参与计算 ​ D.尽量拓展索引，不要新建索引 -已经有a的索引，修改原来索引变成(a,b)即可 有索引但未被用到情况：​ Like 以通配符开头 - ‘%abc’ ‘abc%’ 才用到索引 ​ Where条件不满足我最左匹配原则 ​ 使用!=或&lt;&gt;操作符 ​ 索引列参与计算 ​ 对字段进行null判断 - is null 可以设置默认值0 ​ 使用or链接条件 -使用Union All]]></content>
      <categories>
        <category>NoteBook</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Spring+Shiro+Redis实践]]></title>
    <url>%2FmyBlog%2F2018%2F08%2F08%2FSpring%2BShiro%2BRedis%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"><![CDATA[Apache Shiro是Java的一个安全框架。使用Spring+Shiro+Redis完成登录注册，权限认证的功能。Subject本质上就是当前访问用户的抽象描述。所有 参考张开涛《跟我学Shiro教程》]]></content>
      <categories>
        <category>NoteBook</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JAVA-IO]]></title>
    <url>%2FmyBlog%2F2018%2F05%2F18%2FJAVA-IO%2F</url>
    <content type="text"><![CDATA[设计模式：装饰者模式 漫画解释同步/异步、阻塞/非阻塞 1234567区分同步或异步（synchronous/asynchronous）。1,简单来说，同步是一种可靠的有序运行机制，当我们进行同步操作时，后续的任务是等待当前调用返回，才会进行下一步；2,而异步则相反，其他任务不需要等待当前调用返回，通常依靠事件、回调等机制来实现任务间次序关系。区分阻塞与非阻塞（blocking/non-blocking）。1,在进行阻塞操作时，当前线程会处于阻塞状态，无法从事其他任务， 只有当条件就绪才能继续，比如 ServerSocket 新连接建立完毕，或数据读取、写入操作完成；2,而非阻塞则是不管 IO 操作是否结束，直接返回，相应操作在后台继续处理。 女朋友拉我一起逛街，她去挑选衣服，我坐着玩手机，时不时问她好没好【同步非阻塞】 NIOSnailclimb Java NIO 概览 IO是什么？ IO的全称其实是：Input/Output的缩写 。 BIO、NIO、AIO 的区别是什么？BIO（Blocking） 同步、阻塞：一排烧水壶在烧水，BIO的工作模式是，叫一个线程留着水壶那，直到这个水壶烧开，才去处理下一个水壶。实际上线程在等待水壶烧开的这段时间什么都没做。 NIO(New可以用非阻塞理解 )：工作模式是叫一个线程不断的轮询每个水壶的状态，看看水壶状态是否改变，在进行下一步。提供了 Channel、Selector、Buffer 等新的抽象 ， 可以构建多路复用的、同步非阻塞 IO 程序， AIO（Asynchronous）异步、非阻塞：为每个水壶装一个开关，水烧开后，水壶会通知我水烧开了。异步 IO 操作基于事件和回调机制，可以简单理解为，应用操作直接返回，而不会阻塞在那里，当后台处理完成，操作系统会通知相应线程进行后续工作。 NIOBuffer缓冲区是一个对象，包含一些要写入或者读出的数据。 在NIO库中，所有数据都是用缓冲区处理的。在读取数据时，它是直接读到缓冲区中的；在写入数据时，也是写入到缓冲区中。任何时候访问NIO中的数据，都是通过缓冲区进行操作。 当数据到达时，可以预先被写入缓冲区，再由缓冲区交给线程，因此线程无需阻塞地等待IO。 具体的缓存区有这些：ByteBuffe、CharBuffer、 ShortBuffer、IntBuffer、LongBuffer、FloatBuffer、DoubleBuffer。他们实现了相同的接口：Buffer。 Channel通道我们对数据的读取和写入要通过Channel，它就像水管一样，是一个通道。通道不同于流的地方就是通道是双向的，可以用于读、写和同时读写操作。 Java NIO 中权威的说法：通道是 I/O 传输发生时通过的入口，而缓冲区是这些数据传输的来源或目标。对于离开缓冲区的传输，您想传递出去的数据被置于一个缓冲区，被传送到通道。对于传回缓冲区的传输，一个通道将数据放置在您所提供的缓冲区中。 Channel主要分两大类： SelectableChannel：用户网络读写 FileChannel：用于文件操作 服务器缓冲区：serverBuffer，客户端缓冲区：clientBuffer。 当服务器想向客户端发送数据时，需要调用：clientChannel.write(serverBuffer)。当客户端要读时，调用 clientChannel.read(clientBuffer) 当客户端想向服务器发送数据时，需要调用：serverChannel.write(clientBuffer)。当服务器要读时，调用 serverChannel.read(serverBuffer) Selector多路复用器 通道和缓冲区的机制，使得线程无需阻塞地等待IO事件的就绪，但是总是要有人来监管这些IO事件。这个工作就交给了selector来完成，这就是所谓的同步。 Selector允许单线程处理多个 Channel。如果你的应用打开了多个连接（通道），但每个连接的流量都很低，使用Selector就会很方便。 IO是面向流的，NIO是面向缓冲区的 IO流是阻塞的，NIO流是不阻塞的。 NIO有选择器，而IO没有。 NIO 如何实现多路复用功能？ Java I/O多路复用简单的说，就是用单线程，记录并跟踪每个I/O流(sock)的状态，达到一个线程同时管理多个I/O流的效果 ，这就是Java I/O multiplexing。 图解 深入理解NIO]]></content>
      <categories>
        <category>NoteBook</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
        <tag>基础</tag>
        <tag>IO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring-事物]]></title>
    <url>%2FmyBlog%2F2018%2F02%2F16%2FSpring-%E4%BA%8B%E7%89%A9%2F</url>
    <content type="text"><![CDATA[原子性：要么全部执行成功，要么全部执行失败 一致性：在事务开始之前和事务结束以后，数据库的完整性没有被破坏 隔离性：并发的食物是互相隔离的，一个事物执行不被其他事物影响 持久性：事物一旦提交，对数据库的改变是永久性的 脏读：指在一个事务处理过程里读取了另一个未提交的事务中的数据。 不可重复读：一个事务范围内多次查询却返回了不同的数据值，这是由于在查询间隔，被另一个事务修改并提交了。 幻读：同样的事务操作，在前后两个时间段内执行对同一个数据项的读取，可能出现不一致的结果。幻读和不可重复读都是读取了另一条已经提交的事务 MySQL数据库提供的四种隔离级别： ① Serializable (串行化)：可避免脏读、不可重复读、幻读的发生。 ② Repeatable read (可重复读)：可避免脏读、不可重复读的发生。 ③ Read committed (读已提交)：可避免脏读的发生。 ④ Read uncommitted (读未提交)：最低级别，任何情况都无法保证。 spring事物配置事务隔离级别 隔离级别是指若干个并发的事务之间的隔离程度。TransactionDefinition 接口中定义了五个表示隔离级别的常量： TransactionDefinition.ISOLATION_DEFAULT：这是默认值，表示使用底层数据库的默认隔离级别。对大部分数据库而言，通常这值就是TransactionDefinition.ISOLATION_READ_COMMITTED。 TransactionDefinition.ISOLATION_READ_UNCOMMITTED：该隔离级别表示一个事务可以读取另一个事务修改但还没有提交的数据。该级别不能防止脏读，不可重复读和幻读，因此很少使用该隔离级别。比如PostgreSQL实际上并没有此级别。 TransactionDefinition.ISOLATION_READ_COMMITTED：该隔离级别表示一个事务只能读取另一个事务已经提交的数据。该级别可以防止脏读，这也是大多数情况下的推荐值。 TransactionDefinition.ISOLATION_REPEATABLE_READ：该隔离级别表示一个事务在整个过程中可以多次重复执行某个查询，并且每次返回的记录都相同。该级别可以防止脏读和不可重复读。 TransactionDefinition.ISOLATION_SERIALIZABLE：所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，该级别可以防止脏读、不可重复读以及幻读。但是这将严重影响程序的性能。通常情况下也不会用到该级别。 事务传播行为 所谓事务的传播行为是指，如果在开始当前事务之前，一个事务上下文已经存在，此时有若干选项可以指定一个事务性方法的执行行为。 在TransactionDefinition定义中包括了如下几个表示传播行为的常量： TransactionDefinition.PROPAGATION_REQUIRED：如果当前存在事务，则加入该事务；如果当前没有事务，则创建一个新的事务。这是默认值。 TransactionDefinition.PROPAGATION_REQUIRES_NEW：创建一个新的事务，如果当前存在事务，则把当前事务挂起。 TransactionDefinition.PROPAGATION_SUPPORTS：如果当前存在事务，则加入该事务；如果当前没有事务，则以非事务的方式继续运行。 TransactionDefinition.PROPAGATION_NOT_SUPPORTED：以非事务方式运行，如果当前存在事务，则把当前事务挂起。 TransactionDefinition.PROPAGATION_NEVER：以非事务方式运行，如果当前存在事务，则抛出异常。 TransactionDefinition.PROPAGATION_MANDATORY：如果当前存在事务，则加入该事务；如果当前没有事务，则抛出异常。 TransactionDefinition.PROPAGATION_NESTED：如果当前存在事务，则创建一个事务作为当前事务的嵌套事务来运行；如果当前没有事务，则该取值等价于TransactionDefinition.PROPAGATION_REQUIRED。 数据库范式 第一范式：所有字段值都是不可分解的原子值（属性不可分） 第二范式：也就是说在一个数据库表中，一个表中只能保存一种数据，不可以把多种数据保存在同一张数据库表中。（符合1NF，并且，非主属性完全依赖于码。） 第三范式：每一列数据都和主键直接相关，而不能间接相关。（符合2NF，并且，消除传递依赖）]]></content>
      <categories>
        <category>NoteBook</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
        <tag>基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring-AOP]]></title>
    <url>%2FmyBlog%2F2018%2F01%2F20%2FSpring-AOP%2F</url>
    <content type="text"><![CDATA[3.AOP面向切面编程 OOP面向对象编程的基本单位是类，AOP的基本单位是方法适用于具有横切逻辑的应用场景，例如性能检测、范文控制、事物管理、及日志管理 AOP希望将分散在各个业务逻辑代码中的相同代码通过横向切割的方式抽取到一个独立独立的模块中。 3.1概念和术语 Aspect(切面):切面通常是指一个类，是通知和切入点的结合，@Aspect类注解。 Join point(连接点):程序执行的某个特定位置，例如类初始化前，类初始化后，方法执行前，方法执行后，方法抛出异常时等，Spring只支持方法级别的连接点，即方法执行前，方法执行后，方法抛出异常时， Advice(增强):增强是织入到目标类连接点上的一段程序代码 Pointcut(切点):每个程序类都拥有多个连接点，如一个拥有两个方法的类，这两个方法都是连接点，即连接点是程序类中客观存在的事物 @Pointcut(“”) Introduction(引介):允许向现有的类添加新方法或属性 Target object(目标对象):增强逻辑的织入目标类 AOP proxy(代理):一个类被AOP织入增强后，就产出了一个结果类，它是融合了原类和增强逻辑的代理类 Weaving(织入):织入是将增强添加对目标类具体连接点上的过程AOP有三种织入的方式： a、编译期织入，这要求使用特殊的Java编译器。 b、类装载期织入，这要求使用特殊的类装载器ClassLoader。 c、动态代理织入，在运行期为目标类添加增强生成子类的方式。Spring采用动态代理织入，而AspectJ采用编译期织入和类装载期织入。 3.1.1实现123456&lt;beans&gt; &lt;aop:aspectj-autoproxy poxy-target-class="true"/&gt; &lt;!-- 声明自动为spring容器中那些配置@aspectJ切面的bean创建代理，织入切面。--&gt; &lt;!--表示使用CGLib动态代理技术织入增强。不过即使proxy-target-class设置为false，如果目标类没有声明接口，则spring将自动使用CGLib动态代理。--&gt; &lt;bean id = "testAspect" class="com.test.company.aop.TestAspect" /&gt;&lt;/beans&gt; 1234567891011121314151617181920212223242526//切面就是切点和通知的组合体@Aspectpublic class TestAspect &#123; /** * 切点 */ @Pointcut("execution(*com.test.company.service.Impl.TestImpl.insert(..))")//Pointcut 使用pointcut定义切点 private void insertPointcut()&#123; &#125; /** * 环绕通知 * @param pjp */ @Around("insertPointcut()") public Object insert(ProceedingJoinPoint pjp) throws Throwable&#123;&#125; /** * 前置通知 */ @Before("execution(*com.test.company.service.Impl.TestImpl.insert(..))")//execution(*insert(..)) 切点表达式“execution”为关键字，“*insert(..)”为操作参数 private void Before()&#123; &#125; /** * 后置通知 * returnVal,切点方法执行后的返回值 */ @AfterReturning(value="execution(*com.test.company.service.Impl.TestImpl.insert(..))",returning = "returnVal") private void AfterReturning(Object returnVal)&#123; &#125; &#125; 通知有5种类型如下： before 目标方法执行前执行，前置通知 after 目标方法执行后执行，后置通知 after returning 目标方法返回时执行 ，后置返回通知 after throwing 目标方法抛出异常时执行 异常通知 around 在目标函数执行中执行，可控制目标函数是否执行，环绕通知 3.1.2 相关Java基础知识 代理模式 为某对象提供一个代理，从而通过代理来访问这个对象。 代理模式有三种角色组成: 抽象角色(卖票)：接口 代理角色(车票代售点)：Proxy 真实角色(火车站)：实现 动态代理代理类在程序运行前就已经存在，那么这种代理方式被成为 静态代理静态代理：是在编译class文件时生成得代码逻辑。 JDK动态代理 jdk动态代理是由java内部的反射机制来实现的 主要涉及java.lang.reflect 包中：Proxy和InvocationHandler 使用动态代理需要定义一个位于代理类与委托类之间的中介类,中介类需要实现InvocationHandler定义的横切逻辑，通过反射机制调用目标类的方法，动态的将横切逻辑和业务逻辑编织在一起，InvocationHandler接口只定义了一个invoke方法通过”Proxy”类提供的一个newProxyInstance方法用来创建一个对象的代理对象 JDK动态代理：是JDK自带的功能;是java.lang.reflect.*包提供的方式，它必须借助一个接口才能产生代理对象。 实现代理逻辑类必须去实现InvocationHandler类 1. 建立代理对象和真实对象的关系（blind()） 2. 实现代理逻辑方法（invoke()） CGLIB：是第三方提供的技术;不需要提供接口，只要有一个非抽象类就可以实现。 二者都是通过getProxy()生成代理对象。Spring常用这两种，Mybatis还使用Javassist。拦截器是JDK动态代理。 https://zhuanlan.zhihu.com/p/25522841]]></content>
      <categories>
        <category>NoteBook</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring-IOC]]></title>
    <url>%2FmyBlog%2F2018%2F01%2F16%2FSpring-IOC%2F</url>
    <content type="text"><![CDATA[1.Spring框架简介Spring框架是基于Java平台的，它为开发Java应用提供了全方位的基础设施支持，并且它很好地处理了这些基础设施，所以你只需要关注你的应用本身即可。 Spring可以使用POJO（普通的Java对象，plain old java objects）创建应用，并且可以将企业服务非侵入式地应用到POJO。这项功能适用于Java SE编程模型以及全部或部分的Java EE。 2.Spring模块结构 2.1 IOC 控制反转 IoC也称为依赖注入（DI）是为了解决对象之间的耦合度过高的问题 钟表拥有多个独立的齿轮，这些齿轮相互啮合在一起，齿轮相互啮合在一起，协同工作，共同完成某项任务。如果有一个齿轮出了问题，就可能会影响到整个齿轮组的正常运转。与软件系统中对象之间的耦合关系非常相似 软件专家Michael Mattson提出了IOC理论，用来实现对象之间的“解耦”。 借助于“第三方”实现具有依赖关系的对象之间的解耦，这个“第三方”也就是IOC容器。 哪些方面的控制被反转了呢 获得依赖对象的过程被反转了 所谓依赖注入，就是由IOC容器在运行期间，动态地将某种依赖关系注入到对象之中。 所以，依赖注入(DI)和控制反转(IOC)是从不同的角度的描述的同一件事情，就是指通过引入IOC容器，利用依赖关系注入的方式，实现对象之间的解耦。 把依赖注入应用到软件系统中，再来描述一下这个过程： 对象A依赖于对象B,当对象 A需要用到对象B的时候，IOC容器就会立即创建一个对象B送给对象A。 IOC容器就是一个对象制造工厂，你需要什么，它会给你送去，你直接使用就行了，而再也不用去关心你所用的东西是如何制成的，也不用关心最后是怎么被销毁的，这一切全部由IOC容器包办。 IOC容器设计 是基于BeanFactory和ApplicationContext两个接口。 ApplicationContext是BeanFactory的子接口之一。 BeanFactory是IOC容器定义的最底层接口，ApplicationContext是其中高级接口之一，并且做了许多的拓展。 12ApplicationContext context = new ClassPathXmlApplicationContext("applicationContext.xml");BeanFactory factory = context; BeanFactory和ApplicationContext有什么区别BeanFactory可以理解为含有Bean集合的工厂类。BeanFactory 包含了Bean的定义，以便在接收到客户端请求时将对应的Bean实例化。BeanFactory还能在实例化对象时生成协作类之间的关系。此举将Bean自身从Bean客户端的配置中解放出来。BeanFactory还包含Bean生命周期的控制，调用客户端的初始化方法（Initialization Method）和销毁方法（Destruction Method）。 从表面上看，ApplicationContext如同BeanFactory一样具有Bean定义、Bean关联关系的设置及根据请求分发Bean的功能。 但ApplicationContext在此基础上还提供了其他功能。 （1）提供了支持国际化的文本消息。（2）统一的资源文件读取方式。（3）已在监听器中注册的Bean的事件。以下是三种较常见的 ApplicationContext 实现方式。（1）ClassPathXmlApplicationContext：从ClassPath的XML配置文件中读取上下文，并生成上下文定义。应用程序上下文从程序环境变量中取得。 1ApplicationContext context = new ClassPathXmlApplicationContext(“application.xml”); （2）FileSystemXmlApplicationContext ：由文件系统中的XML配置文件读取上下文。1ApplicationContext context = new FileSystemXmlApplicationContext(“application.xml”); （3）XmlWebApplicationContext：由Web应用的XML文件读取上下文。 2.1.1 相关Java基础知识IOC流程 反射：Java语言允许通过程序化的方式间接对class操作，Class文件由类加载器转载后，JVM形成一份描述Class结构的元信息，通过元信息对象可以获取到构造函数，属性和方法等。 通过这个元信息对象间接的调用Class对象的功能。 几个重要的反射类： ClassLoader，Class，Constructor，和Method ClassLoader：类装载器，把一个类装入到JVM。 需要经过： - 1.装载 - 2.链接 校验 准备 解析 - 3.初始化 2.1.2 IOC容器中转配Bean 1234 &lt;bean class="org.springframework.web.servlet.view.InternalResourceViewResolver"&gt; &lt;property name="prefix" value="/WEB-INF/views/" /&gt; &lt;property name="suffix" value=".jsp" /&gt;&lt;/bean&gt; Spring 支持两种依赖注入方式：属性注入和构造函数注入，还支持工厂方法注入方式。 123456789101112131415161718192021public class SpringBeanFactory &#123; private static BeanFactory beanFactory; private static Logger logger = LoggerFactory.getLogger(SpringBeanFactory.class); public static BeanFactory getBeanFactory() &#123; if (beanFactory == null) &#123; synchronized (BeanFactory.class) &#123; try &#123; String path = Config.getConfigFolder(); if (beanFactory == null) &#123; beanFactory = new FileSystemXmlApplicationContext("/" + path + "aplication-spring-dubbo.xml"); &#125; &#125; catch (Exception e) &#123; logger.error("初始化SpringDubbo Error", e); &#125; &#125; &#125; return beanFactory; &#125;&#125; 自动装配 - autowire=”自动装配类型” byName：根据名称自动匹配 byType：根据类型自动匹配 constructor：与byType类似，它只针对构造函数注入的 autodetect： bean作用域 - scope=”作用域” singleton：在IOC容器中只存在一个实例，以单例的方式存在,默认值 prototype：每次从容器调用Bean时，都返回一个新的实例 request：每次HTTP请求都会创建一个新的Bean，只适用于WebApplicationContext环境 session：同一个HTTP Session共享一个Bean，只适用于WebApplicationContext环境 global-session： 基于注解定义Bean @component可以替代下面三种注解，为了清晰化，建议使用特定的注解 @Repository：DAO层实现类 @Service：Service实现类 @Controller：Service实现类扫描包以应用注解的Bean 1&lt;context:component-scan base-package="com.test.company.*" /&gt; Spring使用@Autowired注解实现Bean依赖注入@Autowired默认按照byType匹配在容器中查找Bean若想希望找不到Bean也不报NoSuchBeanDefinitionException异常，可以使用@Autowired(require=false)@Qualifier注解可以限定Bean的名字 12@Qualifier(&quot;userDaop&quot;)private UserDao userDao; https://www.cnblogs.com/wang-meng/p/5597490.html]]></content>
      <categories>
        <category>NoteBook</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[面试常用手写代码]]></title>
    <url>%2FmyBlog%2F2017%2F10%2F12%2F%E9%9D%A2%E8%AF%95%E5%B8%B8%E7%94%A8%E6%89%8B%E5%86%99%E4%BB%A3%E7%A0%81%2F</url>
    <content type="text"><![CDATA[排序快速排序12345678910111213141516171819202122232425262728static int[] a = &#123;6, 1, 2, 7, 9, 11, 4, 5, 10, 8&#125;;static void quickSort(int left, int right) &#123; int i, j, t, temp; if (left &gt; right) &#123; return; &#125; temp = a[left]; i = left; j = right; while (i != j) &#123; while (a[j] &gt;= temp &amp;&amp; i &lt; j) &#123; j--; &#125; while (a[i] &lt;= temp &amp;&amp; i &lt; j) &#123; i++; &#125; if (i &lt; j) &#123; t = a[i]; a[i] = a[j]; a[j] = t; &#125; &#125; a[left] = a[i]; a[i] = temp; quickSort(left, i - 1); quickSort(i + 1, right);&#125; 归并排序123456789101112131415161718192021222324252627282930313233343536void mergeSort(int[] arr, int start, int end) &#123; if (start &lt; end) &#123; //折半成两个小集合，分别进行递归 int mid = (start + end) / 2; mergeSort(arr, start, mid); mergeSort(arr, mid + 1, end); //把有序小集合，归并成大集合 merge(arr, start, mid, end); &#125; &#125; void merge(int[] arr, int start, int mid, int end) &#123; //开辟额外大集合 int[] temp = new int[end - start + 1]; int p1 = start, p2 = mid + 1, p = 0; //比较两个小集合放入大集合 while (p1 &lt; mid &amp;&amp; p2 &lt; end) &#123; if (arr[p1] &lt;= arr[p2]) &#123; temp[p++] = arr[p1++]; &#125; else &#123; temp[p++] = arr[p2++]; &#125; &#125; //左侧有剩余 while (p1 &lt; mid) &#123; temp[p++] = arr[p1++]; &#125; //右侧有剩余 while (p2 &lt; end) &#123; temp[p++] = arr[p2++]; &#125; //复制回原数组 for (int i = 0; i &lt; temp.length; i++) &#123; arr[i + start] = temp[i]; &#125; &#125; 堆排序 单例双重校验锁volatile 的一个语义禁止指令重排优化。在读取变量的时候直接从内存读取，保证所有线程看到的变量值都是相同的，synchronized关键字锁住类进入Synchronized 临界区以后，还要再做一次判空。因为当两个线程同时访问的时候，线程A构建完对象，线程B也已经通过了最初的判空验证，不做第二次判空的话，线程B还是会再次构建instance对象。 123456789101112131415public class Singleton &#123; private volatile static Singleton instance = null; private Singleton()&#123;&#125; public static Singleton getInstance()&#123; //检查实例，如果不存在，就进入同步代码块 if (instance==null)&#123;// 双重检测机制 synchronized(Singleton.class)&#123;//1 同步锁 类对象加锁 if(instance == null)&#123;//2 双重检测机制 instance = new Singleton();//3 &#125; &#125; &#125; return instance; &#125;&#125; 静态内部类123456789public class Singleton &#123; private static class LazyHolder&#123; private static final Singleton INSTANCE = new Singleton(); &#125; private Singleton()&#123;&#125; public static Singleton getInstance()&#123; return LazyHolder.INSTANCE; &#125;&#125; enum1234567// JVM会组织反射获取枚举类的私有构造方法public enum Singleton &#123; INSTANCE; public void whateverMethod() &#123; &#125;&#125; 链表单链表反转1234567891011121314 Node reverse(Node head) &#123; if (head == null) &#123; return null; &#125; Node prev = null; Node now = head; while (now != null) &#123; Node next = now.next; now.next = prev; prev = now; now = next; &#125; return prev;&#125; 删除重复值1234567891011121314151617181920 Node deleteRepeat(Node head) &#123; if (null == head || null == head.next) &#123; return head; &#125; Node pre = head; Node cur = head.next; while (cur != null) &#123; if (cur.val == pre.val) &#123; pre.next = cur.next; &#125; else &#123; pre = cur; &#125; if (cur.next == null) &#123; return head; &#125; cur = cur.next; &#125; return cur;&#125; 判断链表是否有环123456789101112131415161718192021Node meetingNode(Node head) &#123; if (head == null) &#123; return null; &#125; Node slow = head.next; if (slow == null) &#123; return null; &#125; Node fast = slow.next; while (slow != null &amp;&amp; fast != null) &#123; if (slow == fast) &#123; return fast; &#125; slow = slow.next; fast = fast.next; if (fast != null) &#123; fast = fast.next; &#125; &#125; return null;&#125; 链表中环入口节点1234567891011121314151617181920212223242526272829Node nodeOfLoop(Node head) &#123; if (head == null) &#123; return null; &#125; //得到相遇节点 Node meetingNode = meetingNode(head); if (meetingNode == null) &#123; return null; &#125; //得到环节点数 int nodeInLoopNum = 1; Node p1 = meetingNode; while (p1.next != meetingNode) &#123; p1 = p1.next; ++nodeInLoopNum; &#125; p1 = head; Node p2 = head; //p1先移动环节点数nodeInLoopNum步 for (int i = 0; i &lt; nodeInLoopNum; i++) &#123; p1 = p1.next; &#125; //然后p1,p2以相同速度移动 while (p1 != p2) &#123; p1 = p1.next; p2 = p2.next; &#125; return p1;&#125; 判断两个链表是否相交1234567891011121314boolean isIntersert(Node h1, Node h2) &#123; if (h1 == null || h2 == null) &#123; return false; &#125; Node tail = h1; Node tail2 = h2; while (tail.next != null) &#123; tail = tail.next; &#125; while (tail2.next != null) &#123; tail2 = tail2.next; &#125; return tail == tail2;&#125; 二叉树非递归遍历二叉树 栈：先入后出 123456789101112131415void preOrder(Node head) &#123; if(head != null) &#123; Stack&lt;Node&gt; stack = new Stack&lt;&gt;(); stack.push(head); while(!stack.isEmpty()) &#123; head = stack.pop(); System.out.print(head.val); if (head.right != null) stack.push(head.right); if (head.left != null) stack.push(head.left); &#125; &#125; &#125; 二叉树的深度123456789 int findDeep(BiTree root) &#123; int deep = 0; if(root != null)&#123; int lchilddeep = findDeep(root.left); int rchilddeep = findDeep(root.right); deep = lchilddeep &gt; rchilddeep ? lchilddeep + 1 : rchilddeep + 1; &#125; return deep; &#125; 层次打印二叉树1234567891011121314151617181920212223242526272829void printTree(Tree root) &#123; if (root != null) &#123; //下一层的节点数 int nextLevel = 0; //当前层还没打印的节点说 int tobePrint = 1; Stack&lt;Tree&gt; stack = new Stack&lt;&gt;(); stack.push(root); while (!stack.empty()) &#123; Tree node = stack.pop(); System.out.println(node.value); if (node.left != null) &#123; stack.push(node.left); nextLevel++; &#125; if (node.right != null) &#123; stack.push(node.right); nextLevel++; &#125; tobePrint--; if (tobePrint == 0) &#123; System.out.println("\n"); tobePrint = nextLevel; nextLevel = 0; &#125; &#125; &#125;&#125; 判断tree2是否为tree1子结构1234567891011121314151617181920212223boolean hasSubTree(Tree root1, Tree root2) &#123; boolean result = false; if (root1.value == root2.value) &#123; result = tree1hasTree2(root1, root2); &#125; if (!result) &#123; result = hasSubTree(root1.left, root2); &#125; if (!result) &#123; result = hasSubTree(root1.right, root2); &#125; return result;&#125;boolean tree1hasTree2(Tree root1, Tree root2) &#123; if (root2 == null || root1 == null) &#123; return true; &#125; if (root1.value != root2.value) &#123; return false; &#125; return tree1hasTree2(root1.left, root2.left) &amp;&amp; tree1hasTree2(root1.right, root2.right);&#125; 数组合并两个有序数据，结果任然有序12345678910111213141516171819 int[] merge(int[] a, int[] b) &#123; int[] result; result = new int[a.length + b.length]; int i = 0, j = 0, k = 0; while (i &lt; a.length &amp;&amp; j &lt; b.length) &#123; if (a[i] &lt; b[j]) &#123; result[k++] = a[i++]; &#125; else &#123; result[k++] = b[j++]; &#125; &#125; while (i &lt; a.length) &#123; result[k++] = a[i++]; &#125; while (j &lt; b.length) &#123; result[k++] = b[j++]; &#125; return result;&#125; 二分查找12345678910111213141516int binarySearch(int[] arr, int key) &#123; int low = 0; int high = arr.length - 1; while (low &lt;= high) &#123; int mid = (low + high) / 2; if (key == arr[mid]) &#123; return mid; &#125; else if (key &gt; arr[mid]) &#123; low = mid + 1; &#125; else &#123; high = mid - 1; &#125; &#125; return 0; &#125; 矩阵顺时针打印矩阵剪绳子求最大乘积动态规划 求问题的最优解 整体问题的最优解是依赖各个子问题的最优解 把大问题分解成若干小问题，小问题之间还有互相重叠的更小的子问题 从上往下分析问题，从下往上解决问题 为了避免重复求解子问题通常先计算小问题的最优解并存储下来，在以此基础求取大问题最优解。 123456789101112131415161718192021222324252627int maxCuttingSolution(int length) &#123; if (length &lt;= 2) &#123; return 1; &#125; if (length == 3) &#123; return 2; &#125; int[] products = new int[length + 1]; products[0] = 0; products[1] = 1; products[2] = 2; products[3] = 3; int max = 0; //i是顺序递增的，计算的顺序是自下而上的 for (int i = 4; i &lt;= length; i++) &#123; max = 0; for (int j = 1; j &lt;= i / 2; j++) &#123; //在求f(i)之前，对于每一个j而言，f(j)都已经求解出来了 int product = products[j] * products[i - j]; if (max &lt; product) &#123; max = product; &#125; products[i] = max; &#125; &#125; return products[length]; &#125; 贪婪算法每一步都做最贪婪得选择，基于这个选择，能够得到最优解。12345678910111213141516171819/** * 当长度&gt;=5时，尽可能多剪长度为3得绳子，当剩下绳子长度为4时，把绳子剪成长度为2得绳子 */ int maxCuttingSolution1(int length) &#123; if (length &lt;= 2) &#123; return 1; &#125; if (length == 3) &#123; return 2; &#125; //尽可能剪去长度为3的绳子段 int cutThree = length / 3; if (length - cutThree * 3 == 1) &#123; cutThree -= 1; &#125; int cutTwo = (length - cutThree * 3) / 2; // pow(x, y) 返回 x 的 y 次幂。 return (int) Math.pow(3, cutThree) * (int) Math.pow(2, cutTwo);&#125;]]></content>
      <categories>
        <category>NoteBook</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[synchronized关键字]]></title>
    <url>%2FmyBlog%2F2017%2F10%2F01%2Fsynchronized%2F</url>
    <content type="text"><![CDATA[synchronized是一种同步锁同一时刻只能有一个线程能获取到锁 修饰代码块：同步代码块，作用域是{}里面的代码，作用的对象是调用这个代码块的对象。 修饰方法：同步方法，作用范围是整个方法，作用对象是调用这个方法的对象。 修饰静态的方法：作用范围是整个方法，作用对象是这个类的所有对象。 修饰类：作用范围是synchronized后面括号括起来的部分，作用的对象是这个类的所有对象。 1.synchronized 代码块12345public void run() &#123; synchronized(obj) &#123; //一次只能有一个线程进入 &#125;&#125; synchronized锁住的是括号里的对象，不是代码。当synchronized锁住一个对象时，别的线程也想拿到这个对象的锁，必须等待这个线程执行完释放锁，才能再次给这个对象加锁。 example 1234567891011121314151617181920212223public class SyncThread implements Runnable &#123; private static int count; public SyncThread() &#123; &#125; @Override public void run() &#123; try &#123; String lock = new String(); synchronized (this) &#123;//1 synchronized (lock) 2//synchronized (SyncThread.class)3 System.out.println(Thread.currentThread().getName()+":a begin"); Thread.sleep(500); System.out.println(Thread.currentThread().getName()+":a end"); &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 123456789//1,2,3 public static void main(String[] arg)&#123; SyncThread a = new SyncThread(); Thread t1 = new Thread(a); Thread t2 = new Thread(a); t1.start(); t2.start(); &#125; 12345678910//3 public static void main(String[] arg)&#123; SyncThread a = new SyncThread(); SyncThread b = new SyncThread(); Thread t1 = new Thread(a); Thread t2 = new Thread(b); t1.start(); t2.start(); &#125; 1,3输出 t1—:a begin t1—:a end t2—:a begin t2—:a end 2输出 t2—:a begin t1—:a begin t1—:a end t2—:a end 1是对类的当前实例加锁2是对锁特定的实例加锁3是对该类的所有对象都加了锁，该类所有的对象同一把锁。 1.synchronized 方法123456public synchronized void syncAdd() &#123; //4&#125;public static synchronized void syncAdd() &#123; //5&#125; example 12345678910111213141516171819202122232425262728293031323334353637public class SyncThread &#123; public SyncThread() &#123; &#125; public synchronized void isSyncA() &#123; int i = 5; while( i-- &gt; 0)&#123; System.out.println("funA-"+Thread.currentThread().getName() + " : " + i); try &#123; Thread.sleep(500); &#125; catch (InterruptedException ie)&#123; &#125; &#125; &#125; public synchronized void isSyncB()&#123; int i = 5; while( i-- &gt; 0)&#123; System.out.println("funB-"+Thread.currentThread().getName() + " : " + i); try &#123; Thread.sleep(500); &#125;catch (InterruptedException ie)&#123; &#125; &#125; &#125; public static synchronized void cSync()&#123; int i = 5; while( i-- &gt; 0) &#123; System.out.println("cSync"+Thread.currentThread().getName() + " : " + i); try&#123; Thread.sleep(500); &#125;catch (InterruptedException ie)&#123; &#125; &#125; &#125;&#125; main 1234567891011121314151617181920public static void main(String[] arg)&#123;//4 SyncThread a = new SyncThread(); Thread t1 = new Thread(new Runnable() &#123; @Override public void run() &#123; a.isSyncA(); &#125; &#125;,&quot;t1&quot;); Thread t2 =new Thread(new Runnable() &#123; @Override public void run() &#123; a.isSyncB(); &#125; &#125;,&quot;t2&quot;); t1.start(); t2.start(); &#125; 输出 funA-t1 : 4 funA-t1 : 3 funA-t1 : 2 funA-t1 : 1 funA-t1 : 0 funB-t2 : 4 funB-t2 : 3 funB-t2 : 2 funB-t2 : 1 funB-t2 : 0 1234567891011121314151617181920public static void main(String[] arg)&#123; //5 SyncThread a = new SyncThread(); Thread t1 = new Thread(new Runnable() &#123; @Override public void run() &#123; SyncThread.cSync(); &#125; &#125;,&quot;t1&quot;); Thread t2 =new Thread(new Runnable() &#123; @Override public void run() &#123; SyncThread.cSync(); &#125; &#125;,&quot;t2&quot;); t1.start(); t2.start(); &#125; cSynct1 : 4 cSynct1 : 3 cSynct1 : 2 cSynct1 : 1 cSynct1 : 0 cSynct2 : 4 cSynct2 : 3 cSynct2 : 2 cSynct2 : 1 cSynct2 : 0 4是对象锁3,5得到的锁是类的锁 4是防止多线程同时访问这个对象的synchronized方法，（如果这个对象有多个synchronized方法，只要有一个线程访问了一个synchronized方法，其他的线程不能访问这个对象的任一synchronized方法），不同对象的synchronized方法互不影响。 5是防止多线程中不同实例对象同时访问方法，它对类的所有实例起作用。 synchronized修饰方法内对类变量i++，是线程安全吗？怎样保证安全? 由于i++;操作并不具备原子性，该操作是先读取值，然后写回一个新值，相当于原来的值加上1，分两步完成 。对于相同的实例是可以保证线程安全的。否则则不能保证。使用Volatile，保证变量i的可见性，就可以保证线程安全。 123456789// private static Integer i = 1; Thread t1=new Thread(instance); Thread t2=new Thread(instance); private static volatile Integer i = 1; Thread t1=new Thread(instance1); Thread t2=new Thread(instance2); synchronized (this) &#123;sout(i++)&#125; synchronized的实现原理 Java 虚拟机中的同步(Synchronization)基于进入和退出管程(Monitor)对象实现，无论是显式同步(有明确的 monitorenter 和 monitorexit 指令,即同步代码块)还是隐式同步都是如此。在 Java 语言中，同步用的最多的地方可能是被 synchronized 修饰的同步方法。同步方法 并不是由 monitorenter 和 monitorexit 指令来实现同步的，而是由方法调用指令读取运行时常量池中方法的 ACC_SYNCHRONIZED 标志来隐式实现的。参考]]></content>
      <categories>
        <category>NoteBook</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
        <tag>基础</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[编程规约]]></title>
    <url>%2FmyBlog%2F2017%2F08%2F13%2F%E7%BC%96%E7%A0%81%E8%A7%84%E7%BA%A6%2F</url>
    <content type="text"><![CDATA[编程规约集合 【强制】关于 hashCode 和 equals 的处理，遵循如下规则：1） 只要重写 equals，就必须重写 hashCode。 2） 因为 Set 存储的是不重复的对象，依据 hashCode 和 equals 进行判断，所以 Set 存储的对象必须重写这两个方法。3） 如果自定义对象作为 Map 的键，那么必须重写 hashCode 和 equals。说明：String 重写了 hashCode 和 equals 方法，所以我们可以非常愉快地使用 String 对象作为 key 来使用。 【强制】ArrayList的subList结果不可强转成ArrayList，否则会抛出ClassCastException异常，即 java.util.RandomAccessSubList cannot be cast to java.util.ArrayList。说明：subList 返回的是 ArrayList 的内部类 SubList，并不是 ArrayList 而是 ArrayList 的一个视图，对于 SubList 子列表的所有操作最终会反映到原列表上。 【强制】在 subList 场景中，高度注意对原集合元素的增加或删除，均会导致子列表的遍历、增加、删除产生 ConcurrentModificationException 异常。 【强制】使用集合转数组的方法，必须使用集合的 toArray(T[] array)，传入的是类型完全一样的数组，大小就是 list.size()。说明：使用 toArray 带参方法，入参分配的数组空间不够大时，toArray 方法内部将重新分配内存空间，并返回新数组地址；如果数组元素个数大于实际所需，下标为[ list.size() ]的数组元素将被置为 null，其它数组元素保持原值，因此最好将方法入参数组大小定义与集合元素个数一致。 正例：12345List&lt;String&gt; list = new ArrayList&lt;String&gt;(2); list.add("guan"); list.add("bao"); String[] array = new String[list.size()]; array = list.toArray(array); 反例：直接使用 toArray 无参方法存在问题，此方法返回值只能是 Object[]类，若强转其它类型数组将出现 ClassCastException 错误。 【强制】使用工具类 Arrays.asList()把数组转换成集合时，不能使用其修改集合相关的方法，它的 add/remove/clear 方法会抛出 UnsupportedOperationException 异常。说明：asList 的返回对象是一个 Arrays 内部类，并没有实现集合的修改方法。Arrays.asList体现的是适配器模式，只是转换接口，后台的数据仍是数组。 12String[] str = new String[] &#123; "you", "wu" &#125;;List list = Arrays.asList(str); 第一种情况：list.add(“yangguanbao”); 运行时异常。第二种情况：str[0] = “gujin”; 那么 list.get(0)也会随之修改。 【强制】泛型通配符&lt;? extends T&gt;来接收返回的数据，此写法的泛型集合不能使用 add 方 法，而&lt;? super T&gt;不能使用 get 方法，作为接口调用赋值时易出错。说明：扩展说一下 PECS(Producer Extends Consumer Super)原则：第一、频繁往外读取内容的，适合用&lt;? extends T&gt;。第二、经常往里插入的，适合用&lt;? super T&gt;。 【强制】不要在 foreach 循环里进行元素的 remove/add 操作。remove 元素请使用 Iterator方式，如果并发操作，需要对 Iterator 对象加锁。正例： 12345678910List&lt;String&gt; list = new ArrayList&lt;&gt;(); list.add("1"); list.add("2"); Iterator&lt;String&gt; iterator = list.iterator(); while (iterator.hasNext()) &#123; String item = iterator.next(); if (删除元素的条件) &#123; iterator.remove(); &#125; &#125; ## OOP规约 【推荐】循环体内，字符串的连接方式，使用 StringBuilder 的 append 方法进行扩展。说明：下例中，反编译出的字节码文件显示每次循环都会 new 出一个 StringBuilder 对象，然后进行 append 操作，最后通过 toString 方法返回 String 对象，造成内存资源浪费。反例： 1234String str = "start"; for (int i = 0; i &lt; 100; i++) &#123; str = str + "hello"; &#125; 【推荐】final 可以声明类、成员变量、方法、以及本地变量，下列情况使用 final 关键字： 不允许被继承的类，如：String 类。 不允许修改引用的域对象。 不允许被重写的方法，如：POJO 类的 setter 方法。 不允许运行过程中重新赋值的局部变量。 避免上下文重复使用一个变量，使用 final 描述可以强制重新定义一个变量，方便更好地进行重构。 控制语句 【强制】在高并发场景中，避免使用”等于”判断作为中断或退出的条件。说明：如果并发控制没有处理好，容易产生等值判断被“击穿”的情况，使用大于或小于的区间判断条件来代替。反例：判断剩余奖品数量等于 0 时，终止发放奖品，但因为并发处理错误导致奖品数量瞬间变成了负数，这样的话，活动无法终止。注释规约 【强制】类、类属性、类方法的注释必须使用 Javadoc 规范，使用/*内容/格式，不得使用// xxx 方式。 说明：在 IDE 编辑窗口中，Javadoc 方式会提示相关注释，生成 Javadoc 可以正确输出相应注释；在 IDE 中，工程调用方法时，不进入方法即可悬浮提示方法、参数、返回值的意义，提高阅读效率。 【强制】所有的抽象方法（包括接口中的方法）必须要用 Javadoc 注释、除了返回值、参数、异常说明外，还必须指出该方法做什么事情，实现什么功能。 说明：对子类的实现要求，或者调用注意事项，请一并说明。 【强制】所有的类都必须添加创建者和创建日期。 【强制】所有的枚举类型字段必须要有注释，说明每个数据项的用途。 其他 【强制】注意 Math.random() 这个方法返回是 double 类型，注意取值的范围 0≤x&lt;1（能够取到零值，注意除零异常），如果想获取整数类型的随机数，不要将 x 放大 10 的若干倍然后取整，直接使用 Random 对象的 nextInt 或者 nextLong 方法。 【推荐】及时清理不再使用的代码段或配置信息。说明：对于垃圾代码或过时配置，坚决清理干净，避免程序过度臃肿，代码冗余。正例：对于暂时被注释掉，后续可能恢复使用的代码片断，在注释代码上方，统一规定使用三个斜杠(///)来说明注释掉代码的理由。 异常处理 【强制】有 try 块放到了事务代码中，catch 异常后，如果需要回滚事务，一定要注意手动回滚事务。 【推荐】方法的返回值可以为 null，不强制返回空集合，或者空对象等，必须添加注释充分说明什么情况下会返回 null 值。说明：本手册明确防止 NPE 是调用者的责任。 【推荐】防止 NPE，是程序员的基本修养，注意 NPE 产生的场景：1）返回类型为基本数据类型，return 包装数据类型的对象时，自动拆箱有可能产生 NPE。反例：public int f() { return Integer 对象}， 如果为 null，自动解箱抛 NPE。2） 数据库的查询结果可能为 null。3） 集合里的元素即使 isNotEmpty，取出的数据元素也可能为 null。4） 远程调用返回对象时，一律要求进行空指针判断，防止 NPE。5） 对于 Session 中获取的数据，建议 NPE 检查，避免空指针。6） 级联调用 obj.getA().getB().getC()；一连串调用，易产生 NPE。正例：使用 JDK8 的 Optional 类来防止 NPE 问题。 【参考】对于公司外的 http/api 开放接口必须使用“错误码”；而应用内部推荐异常抛出；跨应用间 RPC 调用优先考虑使用 Result 方式，封装 isSuccess()方法、“错误码”、“错误简短信息”。说明：关于 RPC 方法返回方式使用 Result 方式的理由：1）使用抛异常返回方式，调用方如果没有捕获到就会产生运行时错误。2）如果不加栈信息，只是 new 自定义异常，加入自己的理解的 error message，对于调用端解决问题的帮助不会太多。如果加了栈信息，在频繁调用出错的情况下，数据序列化和传输的性能损耗也是问题。 【参考】避免出现重复的代码（Don’t Repeat Yourself），即 DRY 原则。说明：随意复制和粘贴代码，必然会导致代码的重复，在以后需要修改时，需要修改所有的副本，容易遗漏。必要时抽取共性方法，或者抽象公共类，甚至是组件化。正例：一个类中有多个 public 方法，都需要进行数行相同的参数校验操作，这个时候请抽取：private boolean checkParam(DTO dto) {...} 日志规约 【强制】日志文件至少保存 15 天，因为有些异常具备以“周”为频次发生的特点。 【强制】应用中的扩展日志（如打点、临时监控、访问日志等）命名方式：appName_logType_logName.log。logType:日志类型，如 stats/monitor/access 等；logName:日志描述。这种命名的好处：通过文件名就可知道日志文件属于什么应用，什么类型，什么目的，也有利于归类查找。正例：mppserver 应用中单独监控时区转换异常，如：mppserver_monitor_timeZoneConvert.log说明：推荐对日志进行分类，如将错误日志和业务日志分开存放，便于开发人员查看，也便于通过日志对系统进行及时监控。 【强制】避免重复打印日志，浪费磁盘空间，务必在 log4j.xml 中设置 additivity=false。正例：&lt;logger name=&quot;com.taobao.dubbo.config&quot; additivity=&quot;false&quot;&gt; 【强制】异常信息应该包括两类信息：案发现场信息和异常堆栈信息。如果不处理，那么通过关键字 throws 往上抛出。正例：logger.error(各类参数或者对象 toString() + &quot;_&quot; + e.getMessage(), e); 安全 【强制】表单、AJAX 提交必须执行 CSRF 安全验证。说明：CSRF(Cross-site request forgery)跨站请求伪造是一类常见编程漏洞。对于存在CSRF 漏洞的应用/网站，攻击者可以事先构造好 URL，只要受害者用户一访问，后台便在用户不知情的情况下对数据库中用户参数进行相应修改。 【强制】在使用平台资源，譬如短信、邮件、电话、下单、支付，必须实现正确的防重放的机制，如数量限制、疲劳度控制、验证码校验，避免被滥刷而导致资损。说明：如注册时发送验证码到手机，如果没有限制次数和频率，那么可以利用此功能骚扰到其它用户，并造成短信平台资源浪费。 MySql数据库建表 【强制】表达是与否概念的字段，必须使用 is_xxx 的方式命名，数据类型是 unsigned tinyint（1 表示是，0 表示否）。说明：任何字段如果为非负数，必须是 unsigned。注意：POJO 类中的任何布尔类型的变量，都不要加 is 前缀，所以，需要在设置从 is_xxx 到 Xxx 的映射关系。数据库表示是与否的值，使用 tinyint 类型，坚持 is_xxx 的命名方式是为了明确其取值含义与取值范围。正例：表达逻辑删除的字段名 is_deleted，1 表示删除，0 表示未删除。 【强制】禁用保留字，如 desc、range、match、delayed 等，请参考 MySQL 官方保留字。 【强制】主键索引名为 pk_字段名；唯一索引名为 uk_字段名；普通索引名则为 idx_字段名。说明：pk_ 即 primary key；uk_ 即 unique key；idx_ 即 index 的简称。 【强制】小数类型为 decimal，禁止使用 float 和 double。说明：float 和 double 在存储的时候，存在精度损失的问题，很可能在值的比较时，得到不正确的结果。如果存储的数据范围超过 decimal 的范围，建议将数据拆成整数和小数分开存储。 【强制】如果存储的字符串长度几乎相等，使用 char 定长字符串类型。 【强制】varchar 是可变长字符串，不预先分配存储空间，长度不要超过 5000，如果存储长度大于此值，定义字段类型为 text，独立出来一张表，用主键来对应，避免影响其它字段索引效率。 【强制】表必备三字段：id, gmt_create, gmt_modified。说明：其中 id 必为主键，类型为 bigint unsigned、单表时自增、步长为 1。gmt_create, gmt_modified 的类型均为 datetime 类型，前者现在时表示主动创建，后者过去分词表示被动更新。 【推荐】单表行数超过 500 万行或者单表容量超过 2GB，才推荐进行分库分表。说明：如果预计三年后的数据量根本达不到这个级别，请不要在创建表时就分库分表。 索引 【强制】业务上具有唯一特性的字段，即使是多个字段的组合，也必须建成唯一索引。说明：不要以为唯一索引影响了 insert 速度，这个速度损耗可以忽略，但提高查找速度是明显的；另外，即使在应用层做了非常完善的校验控制，只要没有唯一索引，根据墨菲定律，必然有脏数据产生。 【强制】超过三个表禁止 join。需要 join 的字段，数据类型必须绝对一致；多表关联查询时，保证被关联的字段需要有索引。说明：即使双表 join 也要注意表索引、SQL 性能。 【强制】在 varchar 字段上建立索引时，必须指定索引长度，没必要对全字段建立索引，根据实际文本区分度决定索引长度即可。说明：索引的长度与区分度是一对矛盾体，一般对字符串类型数据，长度为 20 的索引，区分度会高达 90%以上，可以使用 count(distinct left(列名, 索引长度))/count(*)的区分度来确定。 【强制】页面搜索严禁左模糊或者全模糊，如果需要请走搜索引擎来解决。说明：索引文件具有 B-Tree 的最左前缀匹配特性，如果左边的值未确定，那么无法使用此索引。 【推荐】如果有 order by 的场景，请注意利用索引的有序性。order by 最后的字段是组合索引的一部分，并且放在索引组合顺序的最后，避免出现 file_sort 的情况，影响查询性能。正例：where a=? and b=? order by c; 索引：a_b_c反例：索引中有范围查找，那么索引有序性无法利用，如：WHERE a&gt;10 ORDER BY b; 索引a_b 无法排序。 【推荐】利用覆盖索引来进行查询操作，避免回表。说明：如果一本书需要知道第 11 章是什么标题，会翻开第 11 章对应的那一页吗？目录浏览一下就好，这个目录就是起到覆盖索引的作用。正例：能够建立索引的种类分为主键索引、唯一索引、普通索引三种，而覆盖索引只是一种查询的一种效果，用 explain 的结果，extra 列会出现：using index。 【推荐】利用延迟关联或者子查询优化超多分页场景。说明：MySQL 并不是跳过 offset 行，而是取 offset+N 行，然后返回放弃前 offset 行，返回N 行，那当 offset 特别大的时候，效率就非常的低下，要么控制返回的总页数，要么对超过特定阈值的页数进行 SQL 改写。正例：先快速定位需要获取的 id 段，然后再关联：SELECT a.* FROM 表 1 a, (select id from 表 1 where 条件 LIMIT 100000,20 ) b where a.id=b.id 【推荐】SQL 性能优化的目标：至少要达到 range 级别，要求是 ref 级别，如果可以是 consts最好。说明：1）consts 单表中最多只有一个匹配行（主键或者唯一索引），在优化阶段即可读取到数据。2）ref 指的是使用普通的索引（normal index）。3）range 对索引进行范围检索。反例：explain 表的结果，type=index，索引物理文件全扫描，速度非常慢，这个 index 级别比较 range 还低，与全表扫描是小巫见大巫。 【推荐】建组合索引的时候，区分度最高的在最左边。正例：如果 where a=? and b=? ，如果 a 列的几乎接近于唯一值，那么只需要单建 idx_a索引即可。说明：存在非等号和等号混合时，在建索引时，请把等号条件的列前置。如：where c&gt;? and d=? 那么即使 c 的区分度更高，也必须把 d 放在索引的最前列，即索引 idx_d_c。 SQL语句 【强制】不要使用 count(列名)或 count(常量)来替代 count()，count()是 SQL92 定义的标准统计行数的语法，跟数据库无关，跟 NULL 和非 NULL 无关。说明：count(*)会统计值为 NULL 的行，而 count(列名)不会统计此列为 NULL 值的行。 【强制】count(distinct col) 计算该列除 NULL 之外的不重复行数，注意 count(distinctcol1, col2) 如果其中一列全为 NULL，那么即使另一列有不同的值，也返回为 0。 【强制】在代码中写分页查询逻辑时，若 count 为 0 应直接返回，避免执行后面的分页语句。 【推荐】in 操作能避免则避免，若实在避免不了，需要仔细评估 in 后边的集合元素数量，控制在 1000 个之内。 【强制】sql.xml 配置参数使用：#{}，#param# 不要使用${} 此种方式容易出现 SQL 注入。 【强制】不允许直接拿 HashMap 与 Hashtable 作为查询结果集的输出。说明：resultClass=”Hashtable”，会置入字段名和属性值，但是值的类型不可控。 工程结构 【参考】分层领域模型规约： DO（Data Object）：此对象与数据库表结构一一对应，通过 DAO 层向上传输数据源对象。  DTO（Data Transfer Object）：数据传输对象，Service 或 Manager 向外传输的对象。  BO（Business Object）：业务对象，由 Service 层输出的封装业务逻辑的对象。  AO（Application Object）：应用对象，在 Web 层与 Service 层之间抽象的复用对象模型，极为贴近展示层，复用度不高。  VO（View Object）：显示层对象，通常是 Web 向模板渲染引擎层传输的对象。 Query：数据查询对象，各层接收上层的查询请求。注意超过 2 个参数的查询封装，禁止使用 Map 类来传输。 【强制】定义 GAV 遵从以下规则：1） GroupID 格式：com.{公司/BU }.业务线 [.子业务线]，最多 4 级。说明：{公司/BU} 例如：alibaba/taobao/tmall/aliexpress 等 BU 一级；子业务线可选。正例：com.taobao.jstorm 或 com.alibaba.dubbo.register2） ArtifactID 格式：产品线名-模块名。语义不重复不遗漏，先到中央仓库去查证一下。正例：dubbo-client / fastjson-api / jstorm-tool3） Version：详细规定参考下方。 【强制】二方库版本号命名方式：主版本号.次版本号.修订号1） 主版本号：产品方向改变，或者大规模 API 不兼容，或者架构不兼容升级。 2） 次版本号：保持相对兼容性，增加主要功能特性，影响范围极小的 API 不兼容修改。3） 修订号：保持完全兼容性，修复 BUG、新增次要功能特性等。说明：注意起始版本号必须为：1.0.0，而不是 0.0.1 正式发布的类库必须先去中央仓库进行查证，使版本号有延续性，正式版本号不允许覆盖升级。如当前版本：1.3.3，那么下一个合理的版本号：1.3.4 或 1.4.0 或 2.0.0 【强制】线上应用不要依赖 SNAPSHOT 版本（安全包除外）。说明：不依赖 SNAPSHOT 版本是保证应用发布的幂等性。另外，也可以加快编译时的打包构建。 【强制】二方库的新增或升级，保持除功能点之外的其它 jar 包仲裁结果不变。如果有改变，必须明确评估和验证，建议进行 dependency:resolve 前后信息比对，如果仲裁结果完全不一致，那么通过 dependency:tree 命令，找出差异点，进行排除 jar 包。 【强制】二方库里可以定义枚举类型，参数可以使用枚举类型，但是接口返回值不允许使用枚举类型或者包含枚举类型的 POJO 对象。 【强制】依赖于一个二方库群时，必须定义一个统一的版本变量，避免版本号不一致。说明：依赖 springframework-core,-context,-beans，它们都是同一个版本，可以定义一个变量来保存版本：${spring.version}，定义依赖的时候，引用该版本。 【强制】禁止在子项目的 pom 依赖中出现相同的 GroupId，相同的 ArtifactId，但是不同的Version。说明：在本地调试时会使用各子项目指定的版本号，但是合并成一个 war，只能有一个版本号出现在最后的 lib 目录中。可能出现线下调试是正确的，发布到线上却出故障的问题。 【推荐】所有 pom 文件中的依赖声明放在语句块中，所有版本仲裁放在语句块中。说明：里只是声明版本，并不实现引入，因此子项目需要显式的声明依赖，version 和 scope 都读取自父 pom。而所有声明在主 pom 的 里的依赖都会自动引入，并默认被所有的子项目继承。 服务器 【推荐】给 JVM 环境参数设置-XX:+HeapDumpOnOutOfMemoryError 参数，让 JVM 碰到 OOM 场景时输出 dump 信息。说明：OOM 的发生是有概率的，甚至相隔数月才出现一例，出错时的堆内信息对解决问题非常有帮助。 【推荐】在线上生产环境，JVM 的 Xms 和 Xmx 设置一样大小的内存容量，避免在 GC 后调整堆大小带来的压力。]]></content>
      <categories>
        <category>NoteBook</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Volatile关键字]]></title>
    <url>%2FmyBlog%2F2017%2F08%2F01%2Fvolatile%2F</url>
    <content type="text"><![CDATA[Volatile 能够保证可见性。 volatile的两大特性：禁止重排序、内存可见性。 1）保证了不同线程对这个变量进行操作时的可见性，即一个线程修改了某个变量的值，新值对其他线程来说是立即得知的。 2）禁止进行指令重排序。 并发编程中三大概念：原子性，有序性，可见性。 1.原子性一个操作或者多个操作，要么全部执行并且执行过程中不会被任何一个因素打扰，要么就不会执行。Java中，对于基本数据类型的变量读取和赋值操作是原子的。 1234x=10; //1y=x; //2x++; //3x=x+1; //4 只有1是原子的操作。 2是两个操作，先读取x的值，在把x的值写入工作内存，这两个操作都是原子操作，放在一起就不是原子操作了。 3和4都是先读取x的值，在进行加一的操作，写入新的值。 只有简单的读取、赋值（变量之间赋值不是）才是原子操作。 可以通过synchronized和Lock解决原子性问题。 2.可见性线程之间的可见性，一个线程修改共享变量的值，其他的线程能够得知这个修改。 Java中，volatile关键字来保证可见性。被volatile修饰的变量，变量修改的值会立即更新到主内存，每次使用前立即从主内存刷新，当其他线程需要读取的时候。就会读取主存的值。 普通变量被修改的时候，什么时候写入主存是不确定的。当其他线程读取的时候可能还是原来的值，因此无法保证可见性。 synchronized和final能实现可见性 ​ 同步块：对一个变量执行unLock之前，必须把此变量同步回主内存中。 ​ final：被final修饰的字段在构造器中一旦初始化完成， 并且构造器没有把“this”引用传递出去，其他线程就能看见这个final字段的值。 3.有序性程序执行的顺序按照代码先后执行。 指令重排序不会影响单个线程的执行，会影响到线程并发执行的正确性。 Java中允许编译器和处理器对指令进行重排序，volatile、和synchronized都可以保证有序性， 应用场景1.状态标记量 2.double check ### volatile实现原理 happen-before （先行发生原则）：判断数据是否存在竞争，线程是否安全的主要依据。 如果操作A先行发生于B，发生操作B之前，操作A产生的影响能被B观察到。 内存间相互操作 lock：主内存，把变量标识为一条线程独占状态 unlock：主内存，把一个处于锁定状态的变量释放出来，变量才可以被其他线程锁定 read：主内存，把一个变量从主内存传输到线程的工作内存，以便之后的load操作使用 load：工作内存，把 read操作从主内存中得到的变量放入工作内存的变量副本中 use：工作内存，把工作内存的变量值传递给执行引擎，每当虚拟机遇到一个需要使用到变量的值的字节码指令时，将会执行此操作 assign：工作内存，把一个执行引擎护接收到的值赋值给工作内存中变量，每当虚拟机遇到一个需要给变量赋值的指令时执行此操作 store：工作内存，把工作内存中的一个变量值传送到主内存，以便之后的 write使用 write：主内存，把store操作在从工作内存得到的变量值放入主内存中 如果要把一个变量的从主内存复制到工作内存【read load】 如果要把一个变量从工作内存同步到主内存【store write】 java内存模型只要求上述两个操作必须按顺序执行 这8个操作必须满足的规则 不允许read和load、store和write单独使用 不允许一个线程丢弃assign 不允许一个线程无原因的（未发生过任何assign）把数据从线程的工作内存同步主内存 一个新变量之能从 主内存诞生，不允许在工作线程中直接使用一个未被初始化（load，assign）的变量 一个变量同一时刻只允许一条线程对其进行lock操作，lock可以被同一个线程重复多次执行，多次lock，只有执行相同次数的unlock，变量才会被解锁 如果对一个变量执行lock操作，将清空工作内存中此变量的值，在执行引擎使用这个变量时，需要重新执行 load 或assign 如果没有执行过lock，不允许对它执行unlock，也不允许去unlock一个被其他线程锁住的对象 进行unlock之前，必须将此变量 同步主存（store，write） Java 内存模型对Volatile定义的特殊规则定义变量V、W被volatile修饰，线程T会操作变量V和W。下面用浅显的语言解释Java内存模型对其的特殊规则： 每次使用前从主内存读取read、load、use必须顺序整体出现。前一个操作是load时才能use，后一个操作时use时才能load。 每次修改后立即同步回主内存assign、store、write必须顺序整体出现。前一个操作是assign时才能store，后一个操作时store时才能assign。 避免指令重排序 如果T对V的use或者assign先于T对W的use或者assign，那么T对V的load或者write必须先于T对W的load或者assign。 加了volatile关键字的代码生成的汇编代码发现，会多出一个lock前缀指令。Lock指令对Intel平台的CPU，早期是锁总线，这样代价太高了，后面提出了缓存一致性协议，MESI，来保证了多核之间数据不一致性问题。 volatile读操作性能消耗和普通变量几乎没差别，写操作可能会慢一些，因为它需要在本地代码中插入许多内存屏障指令保证处理器不会发生乱序执行。 大多数场景下volatile总开销要比锁低。]]></content>
      <categories>
        <category>NoteBook</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
        <tag>基础</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[垃圾收集算法]]></title>
    <url>%2FmyBlog%2F2017%2F07%2F20%2F%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[1.标记-清除算法最基础的收集算法。分为两个阶段：标记出所有需要回收的对象，标记完成后统一回收所有被标记的对象。不足：效率，空间，标记清除后会产生大量不连续的内存碎片。 不足：1. 效率问题，标记和请求两个操作效率都不高；2.空间问题，会产生大量不连续的空间碎片。 2.复制算法解决效率问题。将可用的内存按容量分为大小相等的两块，每次只使用一块。当一块用完了，将还存活的对象复制到另一块，然后再把已使用过的内存空间一次清理掉。 不足：在对象存活率很高的时，要进行较多的复制操作，效率会比较低。 新生代内存分为一块较大的Eden空间和两个较小的Survivor空间，每次使用Eden和其中一块Survivor。当回收时，将Eden和Survivor中还存活的对象一次性的复制到另外一块Survivor空间，最后清理调Eden和用过的Survivor空间。 内存分配担保：如果另一块Survivor空间没有足够空间存放新生代存活下来的对象时，这些对象将直接通过分配担保机制进入老年代。 3.标记-整理算法复制算法有较多复制操作，效率问题。根据老年代的特点，标记过程与标记-清除算法一样，后续操作让所有存活对象都像一端移动，然后直接清理掉边界以外的内存。 4.分代收集算法在新生代中有大批对象死去，少量存活：复制算法。复制成本少。老年代中对象存活率高，没有额外的空间对他进行担保：就必须使用 标记-清理 或 标记-整理 算法回收。 对象以死吗一共有两种算法， 引用计数算法，每当有一个地方引用它，计数器值就+1，当引用失效时，计数器值-1，计数器值为0的对象就是不可能在使用的。当对象之间互相引用的时候，计数器值不会为0，就永远不会回收。 GC ROOTS可达性分析算法，GC ROOTS作为起点，从这个节点向下搜索，搜索所有走过的路径称为引用链，当一个对象到GC ROOTS没有任何引用链相连时，就是GC ROOTS对这个对象不可达，则证明这个对象不可用。 可以作为GC ROOTS的对象有以下四种： 虚拟机栈（栈帧中的本地变量表）中引用的对象 方法区中类静态属性引用的对象 方法区中常量引用的对象 本地变量栈中JNI（一般说的Native方法）引用的对象 引用引用分为强引用、软引用、弱引用、虚引用。 强引用：指在车光绪代码中最普遍的存在Object obj = new Object()，这类引用，只要强引用存在，垃圾收集器就不会回收。 软引用：用来描述一些还有用但非必须的对象。SoftReference&lt;Object&gt; softRef=new SoftReference&lt;Object&gt;(obj);，在系统要发生内存溢出异常之前，将会把这些对象列进回收范围之中，进行第二次回收。如果这次回收还没有足够内存，才会抛出内存溢出异常。 弱引用：也是描述非必需对象的，强度比软引用更弱，弱引用关联的对象只能生存到下一次垃圾收集发生之前，当垃圾收集器工作室时，无论当前内存是否足够，都会回收掉只被弱引用关联的对象。WeakReference&lt;Object&gt; weakRef = new WeakReference&lt;Object&gt; (obj) 虚引用：被称为幽灵引用或者幻影引用，是最弱的引用。 http://www.importnew.com/13493.html]]></content>
      <categories>
        <category>NoteBook</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java类加载]]></title>
    <url>%2FmyBlog%2F2017%2F07%2F16%2FJAVA-%E7%B1%BB%E5%8A%A0%E8%BD%BD%2F</url>
    <content type="text"><![CDATA[Java虚拟机加载类的全过程包括，加载，验证，准备，解析和初始化。 加载：根据路径找到对应的class文件，导入 验证：确保class字节流中包含信息符合当前虚拟机要求，不会危害虚拟机安全。 准备：准备阶段是正式为类变量分配内存并设置类变量初始值的阶段，这些变量所使用的内存都将在方法区中进行分配。-类变量（static）、不包含实例对象。 ​ public static value =123 ，设置初始值为0。 ​ public static final value =123 ，设置初始值为123。 解析：虚拟机将常量区符号引用转换为直接引用(解析动作主要针对类或接口、字段、类方法、接口方法、方法类型、方法句柄和调用点限定符7类符号引用进行。) 初始化：对静态变量和静态代码块执行初始化工作 何时触发初始化 使用new关键字实例化对象、读取或设置一个类的静态字段（final修饰、已经在编译期把结果放入常量区的静态字段除外）、已经调用一个类的静态方法时。 使用java.lang.reflect包的方法对类进行反射调用的时候。 当初始化一个类，如果它的父类没有进行初始化的时候，先出发父类的初始化。 当虚拟机启动时，用户需要指定一个要执行的子类（包含main方法的类），虚拟机会先初始化这个类。 当使用JDK1.7动态语言支持时，如果一个java.lang.invoke.MethodHandle实例，对应类没有进行初始化，则先触发其初始化。 对于静态字段，只有直接定义这个字段得类才会被初始化，通过子类引用父类定义得静态字段，只会出发父类得初始化。 数组类不通过类加载器创建，是由虚拟机直接创建。 一个类必须与类加载器一起确定唯一性。 类加载器：通过类的全限定名来获取描述此类的二进制字节流，这个动作放在Java虚拟机外部去实现，以便让应用程序自己决定如何去获取所需要的类。实现这个动作的代码模块就是“类加载器”。 Bootstrap ClassLoader(启动类加载器):负责加载系统类(jre/lib/rt.jar) Extension ClassLoader(扩展类加载器):负责加载扩展类(jre/lib/ext/*.jar) Applicaiton ClassLoader(应用程序类加载器):用于加载自己定义编写的类(classpath指定目录或jar中类) User ClassLoader （用户自己实现的加载器） ​ 1比较两个类是否相等，只有这两个类是同一个类加载器加载的前提才有意义。 “双亲委派模型”：从Java虚拟机角度来讲，只存在两个不通的类加载器，一种是启动类加载器（Bootstrap ClassLoader），这个类加载器使用的是C++语言实现，是虚拟机自身的一部分，另一种就是所有其他的加载器，是由Java语言实现，独立于虚拟机外部，并且全部继承自抽象类Java.lang.ClassLoader 工作过程如果一类加载器收到了类加载请求，它首先不会自己尝试加载这个类，而是把请求委派给父类加载器去完成。 只有在父类反馈自己无法完成这个加载任务时，子类加载器才会尝试自己加载。 先检查需要加载的类是否已经被加载，如果没有被加载，则委托父加载器加载，父类继续检查，尝试请父类加载，这个过程是从下——-&gt; 上; 如果走到顶层发现类没有被加载过，那么会从顶层开始往下逐层尝试加载，这个过程是从上 ——&gt; 下; 这种设计有个好处是，如果有人想替换系统级别的类：String.java。篡改它的实现，但是在这种机制下这些系统的类已经被Bootstrap classLoader加载过了，所以并不会再去加载，从一定程度上防止了危险代码的植入。 双亲委派模型的破坏 JAVA热部署实现首先谈一下何为热部署（hotswap），热部署是在不重启 Java 虚拟机的前提下，能自动侦测到 class 文件的变化，更新运行时 class 的行为。Java 类是通过 Java 虚拟机加载的，某个类的 class 文件在被 classloader 加载后，会生成对应的 Class 对象，之后就可以创建该类的实例。默认的虚拟机行为只会在启动时加载类，如果后期有一个类需要更新的话，单纯替换编译的 class 文件，Java 虚拟机是不会更新正在运行的 class。如果要实现热部署，最根本的方式是修改虚拟机的源代码，改变 classloader 的加载行为，使虚拟机能监听 class 文件的更新，重新加载 class 文件，这样的行为破坏性很大，为后续的 JVM 升级埋下了一个大坑。 另一种友好的方法是创建自己的 classloader 来加载需要监听的 class，这样就能控制类加载的时机，从而实现热部署。 热部署步骤： 1、销毁自定义classloader(被该加载器加载的class也会自动卸载)； 2、更新class 3、使用新的ClassLoader去加载class OSGi Class回收JVM中的Class只有满足以下三个条件，才能被GC回收，也就是该Class被卸载（unload）： 该类所有的实例都已经被GC，也就是JVM中不存在该Class的任何实例。 加载该类的ClassLoader已经被GC。 该类的java.lang.Class 对象没有在任何地方被引用，如不能在任何地方通过反射访问该类的方法 参考https://www.cnblogs.com/lanxuezaipiao/p/4138511.htmlhttps://juejin.im/post/57c66f386be3ff005851de05https://juejin.im/post/5a1fad585188252ae93ab953https://www.cnblogs.com/aspirant/p/7200523.html]]></content>
      <categories>
        <category>NoteBook</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM内存分配]]></title>
    <url>%2FmyBlog%2F2017%2F07%2F13%2FJVM%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%2F</url>
    <content type="text"><![CDATA[线程私有的： 程序计数器 虚拟机栈 本地方法栈 线程共享的： 堆 方法区 直接内存 1.程序计数器（PCR）【线程私有】可以看做当前线程所执行的字节码的行号指示器。(通过计数器得值选取下一条需要执行得字节码指令)为了线程切换后能够恢复到正确执行位置，每条线程都需要独立的程序计数器，独立存储。 2.栈（JVM stack）【线程私有】生命周期与线程相同。描述的是Java方法执行的内存模型：每个方法执行的同时都会创建一个栈帧用于存储局部变量表，操作数栈，动态链接方法出口。局部变量表存放了编译期可知得各种基本数据类型（boolean，byte，char，short，int，float，long，double），对象引用和returnAddress类型。每个方法执行到完成，对应着一个栈帧在虚拟机栈中入栈到出栈的过程。 StackOverflowError异常：如果线程请求得栈深度大于虚拟机允许得深度，抛出该异常。 OutOfMemoryError异常：如果拓展时无法申请到足够内存，抛出该异常。 3.本地方法栈（Native Method Stack）【线程私有】与JVM栈相似，本地方法栈是用的是虚拟机的native方法与JVM栈一样会抛出StackOverflowError，OutOfMemoryError异常 4.堆（heap)【线程共享】是Java虚拟机管理内存中最大的一块。是被所有线程共享的一块内存区域，此内存区域唯一目的是存放对象实例，几乎所有的对象及数组都要在这里分配内存。是垃圾回收器管理的主要区域，因此很多时候也被称作“GC堆”。现在收集器采用分代收集算法，所以Java堆还可以细分为：新生代，老年代；在细分（Eden空间，From Survivor空间，To Survivor空间），从内存分配角度来看，线程共享的Java堆可能划分出多个线程私有的分配缓存区（Thread Local Allocation Buffer, TLAB）。Java堆可以位于物理上不连续的空间，但是逻辑上要连续。 OutOfMemoryError：如果堆中没有内存完成实例分配，并且堆也无法再扩展时，抛出该异常。5.方法区（Method）【线程共享】域Java堆一样。是各个线程共享的内存区域，用于存储虚拟机加载的类信息，常量，静态变量，即时编译器编译后的代码等数据。6.运行时常量池（Runtime Constant Pool）是方法区的一部分。Class文件不仅有类的版本，字段，方法，接口描述信息外，还有一项信息是常量池，用于存放编译期生成的各种字面量和符号引用。7.直接内存（Direct Memory）不是虚拟机运行数据区的一部分。NIO（New Input/Output）类，引入一种基于通道（Channel）与缓冲区（Buffer）的I/O方式，可以使用Native函数库直接分配堆外内存。通过一个Java堆DirectByteBuffer对象作为这块内存的引用进行操作。显著提高性能，因为避免了Java堆和Native堆来回复制数据。8、永久代、方法区和元空间之间的关系 《Java虚拟机规范》只是规定了有方法区这么个概念和它的作用，并没有规定如何去实现它。 在1.7之前在(JDK1.2 ~ JDK6)的实现中，HotSpot 使用永久代实现方法区。 在JDK1.8中，元空间取代了永久代，来实现方法区。]]></content>
      <categories>
        <category>NoteBook</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HashMap归纳总结]]></title>
    <url>%2FmyBlog%2F2017%2F05%2F12%2FHashMap%E5%BD%92%E7%BA%B3%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[HashMap 了解HashMap吗？ HashMap是一种键值对（Key-Value）形式的存储结构。 key和value都允许为null。 当key重复的时候会覆盖，value允许重复。 是无序的，不会按照put的顺序排序。 是非线程安全的。 HashMap的Entry是一个单向链表 默认初始长度是16 知道HashMap的工作原理吗？ 内部是一个数组，数组元素Node是实现了Map.Entry(hash,key,value,next)，next非null的时候指向定位相同的另一个Entry。 使用put()传递键和值，先对键调用hashCode()方法，通过hashCode确定bucket位置存储Entry对象。当发生碰撞的时候，使用散列法处理碰撞节点，将旧的Entry的引用赋值给新的Entry的next上，就是一个链表，冲突的节点从链表头部插入，这样插入新的Entry就不需要遍历链表。 通过get()获取对象。 当两个对象的hashCode相同的时候，怎么获取值对象？ get方法先比较hashCode值，如果hashCode相等，就是用equal()方法比较。 == 号与equals()方法的区别:== 基本数据类型比较的是值，对象比较的是对象的地址值。equals()继承自Object类。在所有没有重写equals()方法的类中，equals()内部是==，也是比较的地址值。然而，Java提供的所有类中，绝大多数类都重写了equals()方法，重写后的equals()方法一般都是比较两个对象的值 如果HashMap的大小超过了负载因子(load factor)定义的容量，怎么办？ 默认的负载因子大小为0.75，初始容量是16，,也就是说，当一个map填满了75%的bucket时候，就会发生resize。简单的说就是把bucket扩充为2倍，之后重新计算index，把节点再放到新的bucket中。 重新调整HashMap大小存在什么问题？ 在多线程的情况下，整个HashMap中的元素都需要重新算一遍。rehash，成本非常大。链表中节点的转移可能会出现死循环的情况。 HashMap与HashTable的区别： HashTable不接受为null的键值(key)和值(value) Hashtable是线程安全的也是synchronized在单线程环境下它比HashMap要慢。 HashMap同步？ Map m = Collections.synchronizeMap(hashMap); 高并发下的HashMap Rehash是HashMap在扩容时的一个步骤，HashMap的容量是有限的。使得HashMap达到一定饱和度时，Key映射位置发生冲突的几率会逐渐提高。这时候，HashMap需要扩展它的长度，也就是进行Resize。 Resize的条件是:HashMap.Size &gt;= Capacity * LoadFactor。 Resize要经过两个过程：扩容和ReHash 扩容：创建一个新的Entry空数组，长度是原数组的2倍。 ReHash：遍历原Entry数组，把所有的Entry重新Hash到新数组。为什么要重新Hash呢？因为长度扩大以后，Hash的规则也随之改变。 Hash公式：index = HashCode（Key） &amp; （Length - 1） ConcurrentHashMap 需要线程安全，那么就使用ConcurrentHashMap。分段锁+CAS HashTable是使用synchronized来锁住整张Hash表来实现线程安全。 JDK1.7:一个 ConcurrentHashMap 由一个个 Segment 组成，Segment代表”部分“或”一段“的意思，所以很多地方都会将其描述为分段锁。Segment 内部是由 数组+链表 组成的。(读操作不加锁，由于HashEntry的value变量是 volatile的，也能保证读取到最新的值。) JDK1.8: HashMap类似的数组+链表+红黑树的方式实现，而加锁则采用CAS和synchronized实现。 CAS：内存中的值V ，旧值A，要修改的值B 123if(A==V)&#123; V=B;&#125; 修改失败重新获取内存地址V的当前值，并重新计算想要修改的值。这个重新尝试的过程被称为自旋。 从思想上来说，synchronized属于悲观锁，悲观的认为程序中的并发情况严重，所以严防死守，CAS属于乐观锁，乐观地认为程序中的并发情况不那么严重，所以让线程不断去重试更新。 链表结构中的数据大于8，则将数据结构升级为TreeBin类型的红黑树结构 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172final V putVal(K key, V value, boolean onlyIfAbsent) &#123; if (key == null || value == null) throw new NullPointerException(); //1. 计算key的hash值 int hash = spread(key.hashCode()); int binCount = 0; //一个死循环 for (Node&lt;K,V&gt;[] tab = table;;) &#123; Node&lt;K,V&gt; f; int n, i, fh; if (tab == null || (n = tab.length) == 0) //2. 如果当前table还没有初始化先调用initTable方法将tab进行初始化 tab = initTable(); else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) &#123; //3. tab[i]为null，则直接使用CAS原子操作将值插入即可 if (casTabAt(tab, i, null, new Node&lt;K,V&gt;(hash, key, value, null))) break; // no lock when adding to empty bin &#125; else if ((fh = f.hash) == MOVED)//Node头结点的hash值为MOVED(-1)，则表示需要扩容，此时调用helpTransfer()方法进行扩容； //4. 当前正在扩容 tab = helpTransfer(tab, f); else &#123; V oldVal = null; synchronized (f) &#123;//对这个Node链表或红黑树通过synchronized加锁 if (tabAt(tab, i) == f) &#123; //5. 当前为链表，在链表中插入新的键值对 if (fh &gt;= 0) &#123; binCount = 1; for (Node&lt;K,V&gt; e = f;; ++binCount) &#123; K ek; if (e.hash == hash &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) &#123; oldVal = e.val; if (!onlyIfAbsent) e.val = value; break; &#125; Node&lt;K,V&gt; pred = e; if ((e = e.next) == null) &#123; pred.next = new Node&lt;K,V&gt;(hash, key, value, null); break; &#125; &#125; &#125; // 6.当前为红黑树，将新的键值对插入到红黑树中 else if (f instanceof TreeBin) &#123; Node&lt;K,V&gt; p; binCount = 2; if ((p = ((TreeBin&lt;K,V&gt;)f).putTreeVal(hash, key, value)) != null) &#123; oldVal = p.val; if (!onlyIfAbsent) p.val = value; &#125; &#125; &#125; &#125; // 7.插入完键值对后再根据实际大小看是否需要转换成红黑树 if (binCount != 0) &#123; if (binCount &gt;= TREEIFY_THRESHOLD) treeifyBin(tab, i); if (oldVal != null) return oldVal; break; &#125; &#125; &#125; //8.对当前容量大小进行检查，如果超过了临界值（实际大小*加载因子）就需要扩容 addCount(1L, binCount); return null; &#125; helpTransfer() 中 sizeCtl ABA问题 ​ CAS理解 怎么解决呢？加个版本号就可以了。 （1）ArrayList以数组形式实现，顺序插入、查找快，插入、删除较慢 （2）LinkedList以链表形式实现，顺序插入、查找较慢，插入、删除方便 https://mp.weixin.qq.com/s/SyKckwLfV2ypJOzTFA7R_g https://mp.weixin.qq.com/s/__ZnkPAF6ucUqN8CVSVQeA https://juejin.im/post/5a224e1551882535c56cb940 https://www.jianshu.com/p/5dbaa6707017]]></content>
      <categories>
        <category>NoteBook</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
        <tag>基础</tag>
        <tag>集合</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[准备面试基础]]></title>
    <url>%2FmyBlog%2F2017%2F03%2F01%2F%E9%9D%A2%E7%BB%8F%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[java内存区域, 各个模块的作用线程共享：堆，方法区，直接内存 线程私有的：程序计数器，虚拟机栈，本地方法栈 程序计数器：记录线程执行的位置行数，为了线程切换后能恢复正确的执行位置 虚拟机栈：存储局部变量表，常量池的引用，方法的出口等，一个方法的执行意味着一个栈帧入栈出栈的过程 本地方法栈：与栈类似，它用的是虚拟机的native方法 为保证线程中局部变量不被其他线程访问到，所以虚拟机栈和本地方法栈是线程私有的 堆：是java虚拟机管理内存最大的一块，存储实例对象和数组，是垃圾回收管理主要区域 方法区：存储类信息，常量和静态变量，接口，变量，方法名等描述信息 垃圾回收算法1.引用计数法 给对象中添加一个引用计数器，每当有一个地方引用它，计数器就加1；当引用失效，计数器就减1；任何时候计数器为0的对象就是不可能再被使用的。 不能解决项目引用的问题。 2.可达性分析法 利用JVM对象引用图，从根节点遍历对象应用图，同时标记遍历到的对象。遍历结束后未被标记的对象就是不在使用的对象了 可作为GC Roots的对象包括下面几种: 虚拟机栈(栈帧中的本地变量表)中引用的对象。 方法区中类静态属性引用的对象。 方法区中常量引用的对象。 本地方法栈中JNI(即一般说的Native方法)引用的对象。 1.标记-清除算法 算法分为“标记”和“清除”阶段：首先标记出所有需要回收的对象，在标记完成后统一回收所有被标记的对象。 它是最基础的收集算法，效率也很高，但是会带来两个明显的问题： 效率问题 空间问题（标记清除后会产生大量不连续的碎片） 2.复制算法 它可以将内存分为大小相同的两块，每次使用其中的一块。当这一块的内存使用完后，就将还存活的对象复制到另一块去，然后再把使用的空间一次清理掉。这样就使每次的内存回收都是对内存区间的一半进行回收。 3.标记-整理算法 根据老年代的特点特出的一种标记算法，标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象回收，而是让所有存活的对象向一端移动，然后直接清理掉端边界以外的内存。 4.分代收集算法 根据对象存活周期的不同将内存分为几块。一般将java堆分为新生代和老年代，这样我们就可以根据各个年代的特点选择合适的垃圾收集算法。 堆溢出,栈溢出举例, 内存溢出与泄漏的区别并举例堆OutOfMemoryError(Java heap space)：堆中主要存储的是对象。如果不断的new对象则会导致堆中的空间溢出 -Xms 去调整堆的大小 栈StackOverflowError：创建的栈帧超过了栈的深度，**死循环或递归调用**，-Xss 去调整栈的大小 内存泄露memory leak：1.在堆中申请的空间没有被释放，2。对象已经不在使用还在内存中保留 -Xms10M -Xmx10M控制 原因：1.静态集合类 2.各种连接不显示的close 3.监听器没有删除 4.变量不合理的作用域 内存溢出OutOfMemory：新建对象，对象所需要的内存大于堆剩余空间 -调大-Xmx 原因：代码中存在死循环或循环产生过多重复的对象实体 内存中加载的数据量过于庞大，如一次从数据库取出过多数据 双亲委派模型, java类加载过程,每个过程做了什么加载-&gt;验证-&gt;准备-&gt;解析-&gt;初始化 加载：找到class文件导入 验证：验证class文件正确性 准备：为类变量（静态变量）分配内存和设置初始值，（在方法区分配内存）`public static int value=123;` 解析：给符号引用转变为直接引用 初始化：对静态变量和静态代码块执行初始化工作 双亲委派模型工作过程是：如果一个类加载器收到类加载的请求，它首先不会自己去尝试加载这个类，而是把这个请求委派给父类加载器完成。只有当父加载器在自己的搜索范围内找不到指定的类时，子加载器才会尝试自己去加载。 启动类加载器(Bootstrap ClassLoader)-&gt;扩展类加载器(Extension ClassLoader)-&gt;应用程序类加载器(Application ClassLoader)-&gt;自定义classLoader java中的锁, 乐观锁,悲观锁, 自旋锁等等乐观锁：读取数据时不加锁，在更新操作的时候才对冲突检测 悲观锁：操作数据的时候就上锁，所以整个处理过程数据都是被锁住的，synchronized就是悲观锁 自旋锁：是指当一个线程在获取锁的时候，如果锁已经被其它线程获取，那么该线程将循环等待，然后不断的判断锁是否能够被成功获取，直到获取到锁才会退出循环。 可重入锁:又名递归锁，是指在同一个线程在外层方法获取锁的时候，在进入内层方法会自动获取锁。 ReentrantLock Synchronized 独享锁:是指该锁一次只能被一个线程所持有。 ReentrantLock Synchronized 共享锁:是指该锁可被多个线程所持有。 ReadWriteLock，其读锁是共享锁，其写锁是独享锁 分段锁:其实是一种锁的设计，并不是具体的一种锁，对于ConcurrentHashMap而言，其并发的实现就是通过分段锁的形式来实现高效的并发操作。 当操作不需要更新整个数组的时候，就仅仅针对数组中的一项进行加锁操作 https://www.cnblogs.com/lxmyhappy/p/7380073.html ReentrantLock与synchronized都是可重入锁 ReentrantLock是JDK实现的，synchronized是基于JVM实现的 synchronized由编译器加锁和释放锁，ReentrantLock需要手动 ReentrantLock是公平锁，就是先等待的线程可以先获得锁 ReentrantLock可以分组唤醒线程 ReentrantLock提供中断等待锁的机制lock.lockInterruptibly() volatile的作用, CAS的原理, 在java中哪些地方有用到volatile：保证线程可见性，一个线程修改了变量值，对其他线程是立即可见的 CAS(比较并交换) 解决原子性；操作包含三个操作数 —— 内存位置（V）、预期原值（A）和新值(B)。 如果内存位置的值与预期原值相匹配，那么处理器会自动将该位置值更新为新值 。否则，处理器不做任何操作。 CAS 有效地说明了“我认为位置 V 应该包含值 A；如果包含该值，则将 B 放到这个位置；否则，不要更改该位置，只告诉我这个位置现在的值即可。” https://blog.csdn.net/v123411739/article/details/79561458 线程同步的方式https://www.cnblogs.com/XHJT/p/3897440.html volatile synchronized ReentrantLock ConcurrentHashMap的原理,是如何保证多线程安全的https://www.cnblogs.com/ITtangtang/p/3948786.html 多线程的应用，理解多个线程同时运行，减少线程上下文切换的时间 利用多线程可以提高系统整体并发能力及性能 Java的内存模式：是从主存读取变量，线程吧变量保存在本地内存（寄存器）中，不是直接从主存进行读写， 一个线程修改主存的变量值，另一起还在使用寄存器中拷贝的值，造成数据不一致 volatile变量–多线程间可见 （每次都从主存进行读取） synchronized-一时刻只能有一个线程能获取到锁 原子性：Atomic 是指一个操作是不可中断的。即使是在多个线程一起执行的时候，一个操作一旦开始，就不会被其他线程干扰。 同步异步： 举例同步，你喊我吃饭，如果听见了，就一起去吃饭，如果没听见，你就不停喊，知道我听见才一起去吃饭， 异步，你喊我吃饭，然后自己去吃饭，我听到消息可能立刻走也可能等下班才去吃饭。 LRU原理, LinkedHashMap是如何实现的, LinkedHashMap数据结构源码死锁https://blog.csdn.net/ls5718/article/details/51896159 互斥条件，不剥夺条件，请求等待条件，循环等待 索引索引就是个目录，字典的目录，有了目录就能更快的定位 为了方便我们查找，提高查询的效率。 缺点：索引需要维护成本，索引文件是单独存在的，数据的增删改 会产生会索引的额外操作，可能会影响增删改的速度 原理：没有索引就是遍历整张表去查找 把无序的数据变成有序的查询，把随机变成顺序 1、把创建了索引的列的内容进行排序 2、对排序结果生成倒排表 3、在倒排表内容上拼上数据地址链 4、在查询的时候，先拿到倒排表内容，再取出数据地址链，从而拿到具体数据 使用树形索引，还有哈希索引它适合单条查询 联合索引查询优化, 什么情况会失效, a,b,c分别建索引失效情况mysql存储引擎的对比, 为什么用B+树实现事物的隔离级别，事物的实际应用1.脏读：指在一个事务处理过程里读取了另一个未提交的事务中的数据。 2.不可重复读：一个事务范围内多次查询却返回了不同的数据值，这是由于在查询间隔，被另一个事务修改并提交了。 3.幻读：同样的事务操作，在前后两个时间段内执行对同一个数据项的读取，可能出现不一致的结果。幻读和不可重复读都是读取了另一条已经提交的事务 @Transactional(value = &quot;transactionManager&quot;, propagation = Propagation.REQUIRED,isolation = Isolation.READ_COMMITTED) 隔离级别是指若干个并发的事务之间的隔离程度 DEFAULT :默认的， READ_UNCOMMITTED：读未提交，这个级别的隔离机制无法解决脏读、不可重复读、幻读中的任何一种，因此很少使用 READ_COMMITED：读已提交，即能够读到那些已经提交的数据，自然能够防止脏读，但是无法限制不可重复读和幻读 REPEATABLE_READ：重复读取，明确数据读取出来就是为了更新用的，读取了一条数据，这个事务不结束，别的事务就不可以改这条记录，这样就解决了脏读、不可重复读的问题，但是幻读的问题还是无法解决 SERLALIZABLE：串行化，最高的事务隔离级别，不管多少事务，挨个运行完一个事务的所有子事务之后才可以执行另外一个事务里面的所有子事务，这样就解决了脏读、不可重复读和幻读的问题 HAVING 用法，join用法WHERE 子句用来筛选 FROM 子句中指定的操作所产生的行。 GROUP BY 子句用来分组 WHERE 子句的输出。 HAVING 子句用来从分组的结果中筛选行。 HAVING 语法与 WHERE 语法类似，但 HAVING 可以包含聚合函数。 JOIN（inner join） 只有两个表格都满足条件，才会列出 LEFT JOIN 关键字会从左表那里返回所有的行，即使在右表中没有匹配的行。(RIGHT JOIN同理) TCP可靠传输确认应答（三次四次）,超时重传，流量控制，拥塞控制 校验和：TCP将保持它首部和数据的检验和。 ###### 解决幂等性问题 幂等性：其任意多次执行对资源本身所产生的影响均与一次执行的影响相同，比如支付，下单。 处理方式：每个请求有唯一标识，订单支付请求，订单id 处理完请求后，用一个纪录标识这个请求处理过了，常见方案是在数据库中记录状态 每次接受请求进行判断，比如订单已支付，数据库存在数据就不在处理了 redis请求加锁 乐观悲观锁 http请求header都包含什么？content-type、accept、host、user-agent 5XX错误码500 Internal Server Error：502 Bad Gateway：504 Gateway Timeout： 跨域问题解决12345String origin = request.getHeader("origin");response.setHeader("Access-Control-Allow-Credentials", "true");response.setHeader("Access-Control-Allow-Headers", "*");response.setHeader("Access-Control-Allow-Methods", "POST,GET,OPTIONS");response.setHeader("Access-Control-Allow-Origin", origin); ###### 表单的重复提交 在服务器端生成一个唯一的随机标识号，专业术语称为Token(令牌)，同时在当前用户的Session域中保存这个Token。然后将Token发送到客户端的Form表单中，在Form表单中使用隐藏域来存储这个Token，表单提交的时候连同这个Token一起提交到服务器端，然后在服务器端判断客户端提交上来的Token与服务器端生成的Token是否一致，如果不一致，那就是重复提交了，此时服务器端就可以不处理重复提交的表单。如果相同则处理表单提交，处理完后清除当前用户的Session域中存储的标识号。 ###### 过滤器拦截器应用，区别 filter-&gt;servlet-&gt;intercept-&gt;controller 过滤器：Filter是实现了javax.servlet.Filter接口的服务器端程序 过滤器用途：设置字符集，控制权限，过滤掉非法url， 拦截器： SpringMVC 中的Interceptor 拦截请求是通过HandlerInterceptor 来实现的 拦截器用途：权限检查，如登录检查 创建一个Filter只需两个步骤 创建Filter处理类 web.xml文件中配置Filter 当web应用重新启动或销毁时，Filter也被销毁 void init(FilterConfig config):用于完成Filter的初始化。 void destory():用于Filter销毁前，完成某些资源的回收。 void doFilter(ServletRequest request,ServletResponse response,FilterChain chain):实现过滤功能 拦截器实现 preHandle (HttpServletRequest request, HttpServletResponse response, Object handle) 方法，该方法将在请求处理之前进行调用。当它返回为false 时，表示请求结束，后续的Interceptor 和Controller 都不会再执行； postHandle (HttpServletRequest request, HttpServletResponse response, Object handle, ModelAndView modelAndView) 方法，就是在当前请求进行处理之后，也就是Controller 方法调用之后执行 afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handle, Exception ex) 方法，该方法将在整个请求结束之后，也就是在DispatcherServlet 渲染了对应的视图之后执行。这个方法的主要作用是用于进行资源清理工作的。 过滤器和拦截器的区别： ①拦截器是基于java的反射机制的，而过滤器是基于函数回调。 ②拦截器不依赖servlet容器，过滤器依赖servlet容器。 ③拦截器只能对action请求起作用，而过滤器则可以对几乎所有的请求起作用。 ④拦截器可以访问action上下文、值栈里的对象，而过滤器不能访问。 ⑤在action的生命周期中，拦截器可以多次被调用，而过滤器只能在容器初始化时被调用一次。 ⑥拦截器可以获取IOC容器中的各个bean，而过滤器就不行，这点很重要，在拦截器里注入一个service，可以调用业务逻辑。 原文：https://blog.csdn.net/chenleixing/article/details/44573495]]></content>
      <tags>
        <tag>JAVA</tag>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[准备面试升级]]></title>
    <url>%2FmyBlog%2F2017%2F03%2F01%2F%E9%9D%A2%E7%BB%8F%E5%8D%87%E7%BA%A7%2F</url>
    <content type="text"><![CDATA[spring事务传播特性事务传播行为就是多个事务方法相互调用时，事务如何在这些方法间传播。 propagation_requierd：如果当前没有事务，就新建一个事务，如果已存在一个事务中，加入到这个事务中，这是最常见的选择。 propagation_supports：支持当前事务，如果没有当前事务，就以非事务方法执行。 propagation_mandatory：使用当前事务，如果没有当前事务，就抛出异常。 propagation_required_new：新建事务，如果当前存在事务，把当前事务挂起。 propagation_not_supported：以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。 propagation_never：以非事务方式执行操作，如果当前事务存在则抛出异常。 propagation_nested：如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则执行与propagation_required类似的操作 了解Spring使用到的设计模式吗？说说对MQ理解https://github.com/doocs/advanced-java 作用：解耦、消峰、异步、广播 如果使用 MQ，A 系统产生一条数据，发送到 MQ 里面去，哪个系统需要数据自己去 MQ 里面消费。 如果新系统需要数据，直接从 MQ 里消费即可；如果某个系统不需要这条数据了，就取消对 MQ 消息的消费即可。 这样下来，A 系统压根儿不需要去考虑要给谁发送数据，不需要维护这个代码，也不需要考虑人家是否调用成功、失败超时等情况。 保证消息消费幂等性（重复消费问题） 1.写库时，先跟进主键确认是否已存在 2.redis的set 处理消息丢失问题 生产者 1.使用事物，如果失败就回滚，重试发送消息，成功便提交事务 2.开启confirm模式，持久化queue元数据，将消息持久化到磁盘，消息被持久化到磁盘，再通知生产者， 了解MQ 底层吗为什么要用缓存用缓存，主要有两个用途：高性能、高并发。 高性能：就是说对于一些需要复杂操作耗时查出来的结果，且确定后面不怎么变化，但是有很多读请求，那么直接将查询出来的结果放在缓存中，后面直接读缓存就好。 高并发：缓存是走内存的，内存天然就支撑高并发。 Redis缓存雪崩：缓存挂了，所有请求都打到数据库 缓存雪崩的事前事中事后的解决方案如下。 事前：redis 高可用，主从+哨兵，redis cluster，避免全盘崩溃。 事中：本地 ehcache 缓存 + hystrix 限流&amp;降级，避免 MySQL 被打死。 事后：redis 持久化，一旦重启，自动从磁盘上加载数据，快速恢复缓存数据。 缓存穿透：缓存中查不到，每次去数据库里查，也查不到。就会直接把数据库给打死 解决方式：从数据库中只要没查到，就写一个空值到缓存里去 然后设置一个过期时间，这样的话，下次有相同的 key 来访问的时候，在缓存失效之前，都可以直接从缓存中取数据。 缓存击穿：就是说某个 key 非常热点，访问非常频繁，处于集中式高并发访问的情况，当这个 key 在失效的瞬间，大量的请求就击穿了缓存，直接请求数据库，就像是在一道屏障上凿开了一个洞。 解决方式：可以将热点数据设置为永远不过期；或者基于 redis or zookeeper 实现互斥锁，等待第一个请求构建完缓存之后，再释放锁，进而其它请求才能通过该 key 访问数据。 Redis 过期策略1.定期删除+惰性删除。 所谓定期删除，指的是 redis 默认是每隔 100ms 就随机抽取一些设置了过期时间的 key，检查其是否过期，如果过期就删除。 惰性删除，获取 key 的时候，如果此时 key 已经过期，就删除，不会返回任何东西。 2.走内存淘汰机制---在内存不足容纳新的数据的的时候 a).noeviction : 新写入数据报错 b).allkeys-lru： 在所有键中，删除最近最少使用的键 c).allkeys-random：在所有键中，随机删除某个键 d).volatile-lru： 在设置过期时间的键中，删除最近最少使用的键 e).volatile-random:在设置过期时间的键中，随机删除某个键 f).volatile-ttl： 在设置过期时间的键中，删除最早过期的键 Redis 主从架构 哨兵集群实现高可用一:主从架构 一主多从： 主负责写，并且将数据复制到从节点，从节点负责读 mysql 读写分离主库将变更写到binlog中，当从库连接到主库后， 从库有一个IO线程，将主库的binlog日志copy到自己本地，执行binlog中的日志内容，写入relay log，就是在自己本地再执行一遍sql。 从库同步主库的数据过程是串行化的，也就是主库并行的操作，在从库会串行执行。 高并发场景下，从库数据就会比主库慢，有延时 如果主库突然宕机，数据还没同步到从库时，MySql有两个机制 半同步复制和并行复制 1:主库写入binlog后，强制立即将数据同步到从库，从库写入relay log后，从库会返回ask给主库，主库接收至少一个从库的ask才会认为写操作完成。 2：从库开启多个线程，并行取relay log中不同库的数据，并行重放不同库的日志。 高并发系统设计1.系统拆分 2.缓存 3.MQ 4.分库分表 5.读写分离 6.ElasticSearch 说说一次 rpc 请求的流程？第一步：provider 向注册中心去注册 第二步：consumer 从注册中心订阅服务，注册中心会通知 consumer 注册好的服务 第三步：consumer 调用 provider 第四步：consumer 和 provider 都异步通知监控中心 Dubbo 传输协议：Dubbo缺省协议采用单一长连接和NIO异步通讯， 注册中心挂了可以继续通信吗？ 可以，因为刚开始初始化的时候，消费者会将提供者的地址等信息拉取到本地缓存，所以注册中心挂了可以继续通信。 说说对zk的理解？注解的理解]]></content>
      <tags>
        <tag>JAVA</tag>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常用Linux命令]]></title>
    <url>%2FmyBlog%2F2017%2F01%2F16%2F%E5%B8%B8%E7%94%A8Linux%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[常用指令ls &ensp;&ensp;&ensp;&ensp; 显示文件或目录 -l 列出文件详细信息l(list) -a 列出当前目录下所有文件及目录，包括隐藏的a(all) mkdir &ensp;&ensp;&ensp;&ensp; 创建目录 -p 创建目录，若无父目录，则创建p(parent) cd &ensp;&ensp;&ensp;&ensp; 切换目录 touch &ensp;&ensp;&ensp;&ensp; 创建空文件 echo &ensp;&ensp;&ensp;&ensp; 创建带有内容的文件。 cat &ensp;&ensp;&ensp;&ensp; 查看文件内容 cp &ensp;&ensp;&ensp;&ensp; 拷贝 cp [选项]… [-T] 源 目的 mv &ensp;&ensp;&ensp;&ensp; 移动或重命名 rm &ensp;&ensp;&ensp;&ensp; 删除文件 -r 递归删除，可删除子目录及文件 -f 强制删除 find &ensp;&ensp;&ensp;&ensp; 在文件系统中搜索某文件 wc &ensp;&ensp;&ensp;&ensp; 统计文本中行数、字数、字符数 grep &ensp;&ensp;&ensp;&ensp; 在文本文件中查找某个字符串 rmdir &ensp;&ensp;&ensp;&ensp; 删除空目录 tree &ensp;&ensp;&ensp;&ensp; 树形结构显示目录，需要安装tree包 pwd &ensp;&ensp;&ensp;&ensp; 显示当前目录 ln &ensp;&ensp;&ensp;&ensp; 创建链接文件 more、less &ensp;&ensp;&ensp;&ensp; 分页显示文本文件内容 head、tail &ensp;&ensp;&ensp;&ensp; 显示文件头、尾内容 ctrl+alt+F1 &ensp;&ensp;&ensp;&ensp; 命令行全屏模式 ## 打包压缩相关命令 gzip： bzip2： tar: 打包压缩 -c 归档文件 -x 压缩文件 -z gzip压缩文件 -j bzip2压缩文件 -v 显示压缩或解压缩过程 v(view) -f 使用档名 例：tar -cvf /home/abc.tar /home/abc 只打包，不压缩 tar -zcvf /home/abc.tar.gz /home/abc 打包，并用gzip压缩 tar -jcvf /home/abc.tar.bz2 /home/abc 打包，并用bzip2压缩 当然，如果想解压缩，就直接替换上面的命令 tar -cvf / tar -zcvf / tar -jcvf 中的“c” 换成“x” 就可以了。 ## 系统管理命令 stat &ensp;&ensp;&ensp;&ensp; 显示指定文件的详细信息，比ls更详细 who &ensp;&ensp;&ensp;&ensp; 显示在线登陆用户 whoami &ensp;&ensp;&ensp;&ensp; 显示当前操作用户 hostname &ensp;&ensp;&ensp;&ensp; 显示主机名 uname &ensp;&ensp;&ensp;&ensp; 显示系统信息 top &ensp;&ensp;&ensp;&ensp; 动态显示当前耗费资源最多进程信息 ps &ensp;&ensp;&ensp;&ensp; 显示瞬间进程状态 ps -aux du &ensp;&ensp;&ensp;&ensp; 查看目录大小 du -h /home带有单位显示目录信息 df &ensp;&ensp;&ensp;&ensp; 查看磁盘大小 df -h 带有单位显示磁盘信息 ifconfig &ensp;&ensp;&ensp;&ensp; 查看网络情况 ping &ensp;&ensp;&ensp;&ensp; 测试网络连通 netstat &ensp;&ensp;&ensp;&ensp; 显示网络状态信息 man &ensp;&ensp;&ensp;&ensp; 命令不会用了，找男人 如：man ls clear &ensp;&ensp;&ensp;&ensp; 清屏 alias &ensp;&ensp;&ensp;&ensp; 对命令重命名 如：alias showmeit=”ps -aux” ，另外解除使用unaliax showmeit kill &ensp;&ensp;&ensp;&ensp; 杀死进程，可以先用ps 或 top命令查看进程的id，然后再用kill命令杀死进程。]]></content>
      <categories>
        <category>NoteBook</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leetcode]]></title>
    <url>%2FmyBlog%2F2016%2F10%2F15%2FLeetcode%2F</url>
    <content type="text"><![CDATA[给定一个包括 n 个整数的数组 nums 和 一个目标值 target。找出 nums 中的三个整数，使得它们的和与 target 最接近。返回这三个数的和。假定每组输入只存在唯一答案。例如，给定数组 nums = [-1，2，1，-4], 和 target = 1. 与 target 最接近的三个数的和为 2. (-1 + 2 + 1 = 2).最接近的三数之和 12345678910111213141516171819202122public static int threeSumClosest(int[] nums, int target) &#123; Arrays.sort(nums); int closeNum = nums[0] + nums[1] + nums[2]; for (int i = 0; i &lt; nums.length - 2; i++) &#123; int j = i + 1; int k = nums.length - 1; while (j &lt; k) &#123; int temp = nums[i] + nums[j] + nums[k]; if (Math.abs(temp - target) &lt; Math.abs(closeNum - target)) &#123; closeNum = temp; &#125; if (temp &lt; target) &#123; j++; &#125; else if (temp &gt; target) &#123; k--; &#125; else &#123; return temp; &#125; &#125; &#125; return closeNum;&#125; 在每个树行中找最大值树行中找最大值 12345678输入: 1 / \ 3 2 / \ \ 5 3 9 输出: [1, 3, 9] 1234567891011121314151617181920212223242526272829303132333435List&lt;Integer&gt; largestValues(TreeNode root) &#123; List&lt;Integer&gt; result = new ArrayList&lt;&gt;(); if (root != null) &#123; int nextLevel = 0; int toBePrint = 1; Queue&lt;TreeNode&gt; queue = new LinkedList&lt;&gt;(); queue.offer(root); Integer max = root.val; while (!queue.isEmpty()) &#123; TreeNode node = queue.poll(); if (node.left != null) &#123; queue.offer(node.left); nextLevel++; &#125; if (node.right != null) &#123; queue.offer(node.right); nextLevel++; &#125; toBePrint--; if (max == null) &#123; max = node.val; &#125; if (node.val &gt; max) &#123; max = node.val; &#125; if (toBePrint == 0) &#123; result.add(max); max = null; toBePrint = nextLevel; nextLevel = 0; &#125; &#125; &#125; return result;&#125;]]></content>
      <categories>
        <category>NoteBook</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>算法</tag>
      </tags>
  </entry>
</search>
